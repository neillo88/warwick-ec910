<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Causal Inference – EC910</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">EC910</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-lecture-handouts" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Lecture Handouts</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-lecture-handouts">    
        <li>
    <a class="dropdown-item" href="./handout-1.html">
 <span class="dropdown-text">Handout 1</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./handout-2.html">
 <span class="dropdown-text">Handout 2</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./handout-3.html">
 <span class="dropdown-text">Handout 3</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./handout-4.html">
 <span class="dropdown-text">Handout 4</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./handout-5.html">
 <span class="dropdown-text">Handout 5</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./handout-6.html">
 <span class="dropdown-text">Handout 6</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./handout-7.html">
 <span class="dropdown-text">Handout 7</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./handout-8.html">
 <span class="dropdown-text">Handout 8</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-problem-sets" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Problem Sets</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-problem-sets">    
        <li>
    <a class="dropdown-item" href="./problem-sets/ps-1/problem-set-1.html">
 <span class="dropdown-text">Problem Set 1</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./problem-sets/ps-1/problem-set-1-solutions.html">
 <span class="dropdown-text">Problem Set 1 (Solutions)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./problem-set-2.html">
 <span class="dropdown-text">Problem Set 2</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./problem-set-2-solutions.html">
 <span class="dropdown-text">Problem Set 2 (Solutions)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./problem-set-3.html">
 <span class="dropdown-text">Problem Set 3</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./problem-set-3-solutions.html">
 <span class="dropdown-text">Problem Set 3 (Solutions)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./problem-set-4.html">
 <span class="dropdown-text">Problem Set 4</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./problem-set-4-solutions.html">
 <span class="dropdown-text">Problem Set 4 (Solutions)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./problem-set-5.html">
 <span class="dropdown-text">Problem Set 5</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./problem-set-5-solutions.html">
 <span class="dropdown-text">Problem Set 5 (Solutions)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./problem-set-6.html">
 <span class="dropdown-text">Problem Set 6</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./problem-set-6-solutions.html">
 <span class="dropdown-text">Problem Set 6 (Solutions)</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-additional-material" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Additional Material</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-additional-material">    
        <li>
    <a class="dropdown-item" href="./material-cef.html">
 <span class="dropdown-text">Conditional Expectation Function</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./material-interpretation.html">
 <span class="dropdown-text">Interpreting Linear Models</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./material-dummy.html">
 <span class="dropdown-text">Dummy Variables</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./material-linearalgebra.html">
 <span class="dropdown-text">Linear Algebra</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./material-inference.html">
 <span class="dropdown-text">Statistical Inference</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview"><span class="header-section-number">1</span> Overview</a></li>
  <li><a href="#potential-outcomes-framework" id="toc-potential-outcomes-framework" class="nav-link" data-scroll-target="#potential-outcomes-framework"><span class="header-section-number">2</span> Potential Outcomes Framework</a>
  <ul class="collapse">
  <li><a href="#potential-outcomes" id="toc-potential-outcomes" class="nav-link" data-scroll-target="#potential-outcomes"><span class="header-section-number">2.1</span> Potential outcomes</a></li>
  <li><a href="#multiple-units" id="toc-multiple-units" class="nav-link" data-scroll-target="#multiple-units"><span class="header-section-number">2.2</span> Multiple units</a></li>
  <li><a href="#assignment-mechanism" id="toc-assignment-mechanism" class="nav-link" data-scroll-target="#assignment-mechanism"><span class="header-section-number">2.3</span> Assignment mechanism</a></li>
  <li><a href="#causal-estimands" id="toc-causal-estimands" class="nav-link" data-scroll-target="#causal-estimands"><span class="header-section-number">2.4</span> Causal estimands</a></li>
  <li><a href="#heterogeneity" id="toc-heterogeneity" class="nav-link" data-scroll-target="#heterogeneity"><span class="header-section-number">2.5</span> Heterogeneity</a></li>
  </ul></li>
  <li><a href="#randomized-experiments" id="toc-randomized-experiments" class="nav-link" data-scroll-target="#randomized-experiments"><span class="header-section-number">3</span> Randomized Experiments</a>
  <ul class="collapse">
  <li><a href="#selection" id="toc-selection" class="nav-link" data-scroll-target="#selection"><span class="header-section-number">3.1</span> Selection</a></li>
  <li><a href="#identification" id="toc-identification" class="nav-link" data-scroll-target="#identification"><span class="header-section-number">3.2</span> Identification</a></li>
  <li><a href="#efficiency" id="toc-efficiency" class="nav-link" data-scroll-target="#efficiency"><span class="header-section-number">3.3</span> Efficiency</a></li>
  <li><a href="#stratification" id="toc-stratification" class="nav-link" data-scroll-target="#stratification"><span class="header-section-number">3.4</span> Stratification</a></li>
  <li><a href="#propensity-score" id="toc-propensity-score" class="nav-link" data-scroll-target="#propensity-score"><span class="header-section-number">3.5</span> Propensity score</a></li>
  </ul></li>
  <li><a href="#instrumental-variables" id="toc-instrumental-variables" class="nav-link" data-scroll-target="#instrumental-variables"><span class="header-section-number">4</span> Instrumental Variables</a>
  <ul class="collapse">
  <li><a href="#compliance" id="toc-compliance" class="nav-link" data-scroll-target="#compliance"><span class="header-section-number">4.1</span> Compliance</a></li>
  <li><a href="#identification-1" id="toc-identification-1" class="nav-link" data-scroll-target="#identification-1"><span class="header-section-number">4.2</span> Identification</a></li>
  <li><a href="#estimation" id="toc-estimation" class="nav-link" data-scroll-target="#estimation"><span class="header-section-number">4.3</span> Estimation</a></li>
  <li><a href="#reduced-form" id="toc-reduced-form" class="nav-link" data-scroll-target="#reduced-form"><span class="header-section-number">4.4</span> Reduced form</a></li>
  </ul></li>
  <li><a href="#observational-studies" id="toc-observational-studies" class="nav-link" data-scroll-target="#observational-studies"><span class="header-section-number">5</span> Observational Studies</a>
  <ul class="collapse">
  <li><a href="#common-support" id="toc-common-support" class="nav-link" data-scroll-target="#common-support"><span class="header-section-number">5.1</span> Common support</a></li>
  <li><a href="#matching" id="toc-matching" class="nav-link" data-scroll-target="#matching"><span class="header-section-number">5.2</span> Matching</a></li>
  <li><a href="#regression" id="toc-regression" class="nav-link" data-scroll-target="#regression"><span class="header-section-number">5.3</span> Regression</a></li>
  </ul></li>
  <li><a href="#difference-in-differences" id="toc-difference-in-differences" class="nav-link" data-scroll-target="#difference-in-differences"><span class="header-section-number">6</span> Difference-in-Differences</a>
  <ul class="collapse">
  <li><a href="#group-2-period" id="toc-group-2-period" class="nav-link" data-scroll-target="#group-2-period"><span class="header-section-number">6.1</span> 2-group-2-period</a></li>
  <li><a href="#parallel-trends" id="toc-parallel-trends" class="nav-link" data-scroll-target="#parallel-trends"><span class="header-section-number">6.2</span> Parallel trends</a></li>
  <li><a href="#regression-1" id="toc-regression-1" class="nav-link" data-scroll-target="#regression-1"><span class="header-section-number">6.3</span> Regression</a></li>
  <li><a href="#group-multi-period" id="toc-group-multi-period" class="nav-link" data-scroll-target="#group-multi-period"><span class="header-section-number">6.4</span> 2-group-multi-period</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading"><span class="header-section-number">6.5</span> Further reading</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">7</span> References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="handout-8.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Causal Inference</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="overview" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="overview"><span class="header-section-number">1</span> Overview</h2>
<p>In this note we will review some more contemporary topics from the field of Microeconometrics. These are the literatures related to Causal Inference, Treatment Effects, and Policy Evaluation. We will not be able to cover everything. In this handout we will discuss:</p>
<ol type="1">
<li>The Potential Outcomes Framework</li>
<li>Randomized Experiments</li>
<li>Instrumental Variables</li>
<li>Observational Studies</li>
<li>Difference-in-Differences</li>
</ol>
<p>Topics that we will not be able to cover include:</p>
<ol type="1">
<li>Staggered-DiD or Event-studies</li>
<li>Synthetic Control</li>
<li>Regression Discontinuity Designs</li>
</ol>
<p>Further reading can be found in:</p>
<ul>
<li>Chapters 2.7, 25.1-25.3, 25.5, 25.8 of <span class="citation" data-cites="cameron2005">Cameron and Trivedi (<a href="#ref-cameron2005" role="doc-biblioref">2005</a>)</span></li>
<li>Section 7.7 of <span class="citation" data-cites="verbeek2017">Verbeek (<a href="#ref-verbeek2017" role="doc-biblioref">2017</a>)</span></li>
</ul>
<p>Some other texts on the topic include:</p>
<ul>
<li><p><strong>(MHE)</strong> <span class="citation" data-cites="angrist2009">Angrist and Pischke (<a href="#ref-angrist2009" role="doc-biblioref">2009</a>)</span> <em>Mostly Harmless Econometrics: An Empiricist’s Companion</em>. Princeton, NJ: Princeton University Press.</p></li>
<li><p><span class="citation" data-cites="angrist2014mastering">Angrist (<a href="#ref-angrist2014mastering" role="doc-biblioref">2014</a>)</span> <em>Mastering Metrics: The Path from Cause to Effect</em>. Princeton, NJ: Princeton University Press.</p></li>
<li><p><strong>(IR)</strong> <span class="citation" data-cites="imbens2015">Imbens and Rubin (<a href="#ref-imbens2015" role="doc-biblioref">2015</a>)</span> <em>Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction</em>. Cambridge, UK: Cambridge University Press</p></li>
<li><p><span class="citation" data-cites="cunningham2021causal">Cunningham (<a href="#ref-cunningham2021causal" role="doc-biblioref">2021</a>)</span> <em>Causal inference: The Mixtape</em>. Yale University Press.</p></li>
</ul>
<p>MHE is more technical than <em>Matering ’Metrics</em>, but with the foundation provided in this module, you should get through much of the content. Note, it was published in 2009 and does not include some more recent topics.</p>
<p>Here are a few papers worth reading:</p>
<ul>
<li><span class="citation" data-cites="angrist2001instrumental">Angrist and Krueger (<a href="#ref-angrist2001instrumental" role="doc-biblioref">2001</a>)</span></li>
<li><span class="citation" data-cites="heckman2008econometric">Heckman (<a href="#ref-heckman2008econometric" role="doc-biblioref">2008</a>)</span></li>
<li><span class="citation" data-cites="imbens2009recent">Imbens and Wooldridge (<a href="#ref-imbens2009recent" role="doc-biblioref">2009</a>)</span></li>
<li><span class="citation" data-cites="angrist2010credibility">Angrist and Pischke (<a href="#ref-angrist2010credibility" role="doc-biblioref">2010</a>)</span></li>
<li><span class="citation" data-cites="athey2017state">Athey and Imbens (<a href="#ref-athey2017state" role="doc-biblioref">2017</a>)</span></li>
</ul>
</section>
<section id="potential-outcomes-framework" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="potential-outcomes-framework"><span class="header-section-number">2</span> Potential Outcomes Framework</h2>
<p>The notion of a ‘causal effect’ is bound by framework within which you define causal effect. In this handout we will build upon the Potential Outcomes (PO) Framework attributed to Jerzy Neyman and Donald Rubin. There are other frameworks, including traditional Econometrics, that seek to model causal relationships <span class="citation" data-cites="heckman2024econometric">(see <a href="#ref-heckman2024econometric" role="doc-biblioref">Heckman and Pinto 2024</a>)</span>. Recently, a lot of consideration has been given to the Dynamic Acyclic Graphs approach popularized by Judea Pearl <span class="citation" data-cites="pearl2018 imbens2020potential heckman2024econometric">(see <a href="#ref-pearl2018" role="doc-biblioref">Pearl and Mackenzie 2018</a>; also <a href="#ref-imbens2020potential" role="doc-biblioref">Imbens 2020</a>; <a href="#ref-heckman2024econometric" role="doc-biblioref">Heckman and Pinto 2024</a>)</span>. For those interested in the broader question of causality within Economics, take a look at <span class="citation" data-cites="hoover2008">Hoover (<a href="#ref-hoover2008" role="doc-biblioref">2008</a>)</span>.</p>
<p>The following is an adaption of the paracetomal example in <span class="citation" data-cites="imbens2015">Imbens and Rubin (<a href="#ref-imbens2015" role="doc-biblioref">2015, 5</a>)</span>:</p>
<div id="exm-tax" class="theorem example">
<p><span class="theorem-title"><strong>Example 1</strong></span> Consider a new hypothetical policy in the UK, wherein time spent studying in the UK counted towards permanent residency (‘indefinite leave to remain’). How would this affect your decision to apply for a graduate visa upon graduation?</p>
<p>There are four potential scenarios:</p>
<ol type="1">
<li>Apply under new rule only:</li>
</ol>
<p><span class="math display">\[Y (\text{reform}) = \text{apply} \qquad{and}\qquad Y (\text{status quo}) = \text{don’t apply}\]</span></p>
<ol start="2" type="1">
<li>Don’t apply in either case:</li>
</ol>
<p><span class="math display">\[Y (\text{reform}) = \text{don't apply} \qquad{and}\qquad Y (\text{status quo}) = \text{don’t apply}\]</span></p>
<ol start="3" type="1">
<li>Apply regardless:</li>
</ol>
<p><span class="math display">\[Y (\text{reform}) = \text{apply} \qquad{and}\qquad Y (\text{status quo}) = \text{apply}\]</span></p>
<ol start="4" type="1">
<li>Don’t apply with new rule, but under status quo:</li>
</ol>
<p><span class="math display">\[Y (\text{reform}) = \text{don't apply} \qquad{and}\qquad Y (\text{status quo}) = \text{apply}\]</span> We say that in scenarios (2) and (3) there is no causal effect, while in scnearios (1) and (4) there is a causal effect.</p>
</div>
<p>Notice two things about this definition of causal effect:</p>
<ul>
<li><p>“First, the definition of the causal effect depends on the potential outcomes, but it does not depend on which outcome is actually observed.” <span class="citation" data-cites="imbens2015">(<a href="#ref-imbens2015" role="doc-biblioref">Imbens and Rubin 2015, 6</a>)</span></p></li>
<li><p>“Second, the causal effect is the comparison of potential outcomes, for the same unit, at the same moment in time post-treatment. In particular, the causal effect is not defined in terms of comparisons of outcomes at different times.” <span class="citation" data-cites="imbens2015">(<a href="#ref-imbens2015" role="doc-biblioref">Imbens and Rubin 2015, 6</a>)</span></p></li>
</ul>
<p>There are three important components to the Potential Outcomes framework:</p>
<ol type="1">
<li><p><strong>Potential outcomes:</strong> the outcomes corresponding to different levels of treatment or manipulation: “no causation without manipulation” <span class="citation" data-cites="rubin1975bayesian">(<a href="#ref-rubin1975bayesian" role="doc-biblioref">Rubin 1975, 238</a>)</span>.</p></li>
<li><p><strong>Multiple units:</strong> given the limitation of observation, one must observe multiple units to infer a causal effect.</p></li>
<li><p><strong>Assignment mechanism:</strong> what determines treatment?</p></li>
</ol>
<section id="potential-outcomes" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="potential-outcomes"><span class="header-section-number">2.1</span> Potential outcomes</h3>
<p>For a discrete treatment, we denote the PO of outcome Y as,<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p><span class="math display">\[
\begin{aligned}
    Y_i(1)\quad&amp;\text{if}\quad D_i=1 \\
    Y_i(0)\quad&amp;\text{if}\quad D_i=0
\end{aligned}
\]</span> where <span class="math inline">\(D_i=\mathbf{1}\{\text{treated}\}\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> The observed outcome, <span class="math inline">\(Y^{obs}_i\)</span>, can written as</p>
<p><span class="math display">\[
\begin{aligned}
    Y^{obs}_i=Y_i(D_i)&amp;=Y_i(0)+D_i\cdot\left(Y_i(1)-Y_i(0)\right) \\
    &amp;=(1-D_i)Y_i(0)+D_iY_i(1)
\end{aligned}
\]</span></p>
</section>
<section id="multiple-units" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="multiple-units"><span class="header-section-number">2.2</span> Multiple units</h3>
<p>We cannot observe both POs for any unit <span class="math inline">\(i\)</span> (in the same period of time). At a fundamental level, this means that we cannot observe the unit-level treatment effect:</p>
<p><span class="math display">\[
\tau_i = Y_i(1)-Y_i(0)
\]</span> We always need to learn about <span class="math inline">\(f_{(1)}\)</span> and <span class="math inline">\(f_{(0)}\)</span> - the marginal distributions of each potential outcome - from two (or more) samples; be this,</p>
<ul>
<li>different units at the same time;</li>
<li>the same units at different times;</li>
<li>or a combination of both.</li>
</ul>
<p>This requires us to make an important assumption: the Stable Unit Treatment Value Assumption (SUTVA).</p>
<div id="def-SUTVA" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1</strong></span> <strong>- SUTVA</strong> “The potential outcomes for any unit do not vary with the treatments assigned to other units, and, for each unit, there are no different forms or versions of each treatment level, which lead to different potential outcomes.” <span class="citation" data-cites="imbens2015">(<a href="#ref-imbens2015" role="doc-biblioref">Imbens and Rubin 2015, 10</a>)</span></p>
</div>
<p>This assumption does two things. First, it rules out interference between treatment units. This rules out any spillover effects between ‘treatment’ and ‘control’. Second, it ensures that there are no hidden variations in the treatment level. It is okay for there to be different levels of treatment, so long as they are explicit and well-defined <em>a priori</em>.</p>
<p>General equilibrium effects violate SUTVA. In almost all case, we need to assume a partial equilibrium setting. As Economists, this means that the PO framework cannot be used to answer all important empirical questions. There remains a value to more structural models that can identify general equilibrium effects.</p>
</section>
<section id="assignment-mechanism" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="assignment-mechanism"><span class="header-section-number">2.3</span> Assignment mechanism</h3>
<p>In experimental data, the assignment mechanism is randomization, while in observational data the assignment mechanism is not known.</p>
<p><em>Randomization is an assignment mechanism</em> that ensures independence/unconfoundedness between the potental outcomes and treatment assignment. This can either be unconditional,<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p><span class="math display">\[
Y_i(1),Y_i(0)\perp D_i
\]</span> or conditional on a set of known covariates, <span class="math display">\[
Y_i(1),Y_i(0)\perp D_i|X_i
\]</span> The latter is also referred to as the Conditional Independence Assumption (as in MHE &amp; MM) and (strong) ignorability. Both assumptions are referred to as unconfoundedness in the literature.</p>
<p>Note, “[w]ithout unconfoundedness, there is no general approach to estimating treatment effects.” <span class="citation" data-cites="imbens2009recent">(<a href="#ref-imbens2009recent" role="doc-biblioref">Imbens and Wooldridge 2009, 7</a>)</span>. Randomization gives you unconfoundedness, but unconfoundedness can be assumed without randomization; for example, in observational studies. In such cases, you might say it is <em>as if</em> assignment is randomized (conditional on X).</p>
<p>Note, in our study of linear models, we made conditional <em>mean</em> independence assumptions of the form <span class="math inline">\(E[\varepsilon_i|X_i]=0\)</span>. Mean independence is sufficient for identification in linear models; however, randomization gives you independence between treatment assignment and potential outcomes. You can therefore identify the the marginal distributions <span class="math inline">\(f_{(0)}\)</span> and <span class="math inline">\(f_{(1)}\)</span> and not just their mean <span class="math inline">\(E[Y(0)]\)</span> and <span class="math inline">\(E[Y(1)]\)</span>.</p>
</section>
<section id="causal-estimands" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="causal-estimands"><span class="header-section-number">2.4</span> Causal estimands</h3>
<p>We cannot identify the unit-level treatment effect, even with randomization. For this reason, the literature focuses on identifying particular causal estimands.</p>
<p>Using the linearity of expectation function, we can identify (from different samples) the Average Treatment Effect from the difference in <em>uncondtional</em> means:</p>
<p><span class="math display">\[
  E[Y_i(1)]-E[Y_i(0)] = E[Y_i(1)-Y_i(0)] = ATE
\]</span> Similarly, we can identify the Average Treatment Effect of the Treated (ATT) and the Untreated (ATU):</p>
<p><span class="math display">\[
\begin{aligned}
  E[Y_i(1)|D_i=1]-E[Y_i(0)|D_i=1] =&amp; E[Y_i(1)-Y_i(0)|D_i=1] = ATT \\
  E[Y_i(1)|D_i=0]-E[Y_i(0)|D_i=0] =&amp; E[Y_i(1)-Y_i(0)|D_i=0] = ATU \\
\end{aligned}
\]</span></p>
<p>The above statements are non-trivial. We can learn about the mean of the unit-level treatment effect from different samples. This follows from the fact that the expectation (or average) operator is linear. Unfortunately, this DOES NOT extend beyond the mean.</p>
<p>The q-th percentile of the distribution of unit-level treatment effects, cannot <em>necessarily</em> be written as the difference between q-th percentile of <span class="math inline">\(f_{(0)}\)</span> and <span class="math inline">\(f_{(1)}\)</span>.</p>
<p><span class="math display">\[
F^{-1}_{(1)-(0)}(q) \neq F^{-1}_{(1)}(q)-F^{-1}_{(0)}(q)
\]</span></p>
<p>For the above to be an equality, there must be perfect rank correlation between the distributions of <span class="math inline">\(Y(1)\)</span> and <span class="math inline">\(Y(0)\)</span>.</p>
<p>There are additional causal estimands important within this literature:</p>
<ul>
<li><p>Conditional ATE, ATT, and ATU; e.g., <span class="math display">\[
ATE(X_i) = E[Y_i(1)-Y_i(0)|X_i]
\]</span></p></li>
<li><p>Average Causal Effect, typically used to describe continuous (or mutliple dosage) treatments; e.g., <span class="math display">\[
ACE(s) = E[Y_i(s+1)-Y_i(s)|S_i=s]
\]</span></p></li>
<li><p>Local Average Treatment Effects (LATE), as identified by instrumenal variables and regression discontinuity designs.</p></li>
<li><p>Cohort-specific ATT, the ATT for a specific treatment cohort in a staggered difference-in-differences (or event-study); e.g., as denoted by <span class="citation" data-cites="sun2021estimating">Sun and Abraham (<a href="#ref-sun2021estimating" role="doc-biblioref">2021</a>)</span></p></li>
</ul>
<p><span class="math display">\[
CATT(c) = E[Y_i(c)-Y_i(\infty)]
\]</span> where <span class="math inline">\(Y_i(\infty)\)</span> denotes the PO when “never-treated”.</p>
<p>I have ignored an important distinction between finite-sample and super-population estimands. The distinction comes down to whether you think of the sample as the population - in which case, the vectors <span class="math inline">\(Y(1)\)</span> and <span class="math inline">\(Y(0)\)</span> are non-random vectors - or whether you think of the sample as a random draw from a (infinite) super-population. The distinction has important implications for how you compute the variance of an estimator <span class="citation" data-cites="imbens2015">(see <a href="#ref-imbens2015" role="doc-biblioref">Imbens and Rubin 2015, chap. 6</a>)</span>. Finite-sample estimands are typically written as averages; hence, the name ‘average’ TEs. For exaemple, the finite-sample ATE is given by, <span class="math display">\[
ATE^{fs} = \frac{1}{N} \sum_{i=1}^{N} Y_i(1)-Y_i(0)
\]</span> The above is an estimand and cannot be computed as it requires you to observe the unit-level treatment effect for all <span class="math inline">\(i\)</span>.</p>
</section>
<section id="heterogeneity" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="heterogeneity"><span class="header-section-number">2.5</span> Heterogeneity</h3>
<p>It is important to recognise that treatment effects need not be homogeneous.</p>
<div id="def-homoTE" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 2</strong></span> <strong>- Homogenous TEs</strong> <span class="math display">\[
Y_i(1)-Y_i(0) = \tau \qquad \forall\;i=1,\dots,n
\]</span></p>
</div>
<p>Indeed, you could argue that this literature is largely focused on the estimation of heterogeneous treatment effects. Homogenous treatment effects negate the need to speak about the ATE, ATT, and ATU as all estimands are equivalent and equal to the unit-level TE.</p>
<p>Heterogeneity also has important implications for the use of models to estimate TEs. Consider, if TEs are homogenous, we can write the observed outcome as,</p>
<p><span class="math display">\[
\begin{aligned}
Y_i =&amp; Y_i(0) + \tau D_i \\
=&amp; E[Y_i(0)] + \tau D_i + Y_i(0)-E[Y_i(0)] \\
=&amp; \alpha + \tau D_i + \varepsilon_i
\end{aligned}
\]</span> We can express the observed outcome as a model that is linear in parameters with an error term that is homoskedastic (assuming <span class="math inline">\(Y_i(0)\)</span> is drawn from the same distribution).</p>
<p>With heterogeneous TEs, we get</p>
<p><span class="math display">\[
\begin{aligned}
Y_i =&amp; Y_i(0) + \tau_i D_i \\
=&amp; E[Y_i(0)] + \tau_{ATE} D_i + Y_i(0)-E[Y_i(0)]+ (\tau_i-\tau_{ATE})D_i \\
=&amp; \alpha + \tau_{ATE} D_i + \upsilon_i
\end{aligned}
\]</span> The model only explains the average difference between the treated and control. The heterogeneity remains in the error term. With random assignment, the error term remains conditionally mean independent; however, it is no longer homoskedastic <span class="citation" data-cites="deaton2010instruments">(see <a href="#ref-deaton2010instruments" role="doc-biblioref">Deaton 2010</a>)</span>.</p>
<p>In models that include a time dimension - e.g., difference-in-differences - you also need to cosider whether TEs are static. ::: {#def-staticTE} <strong>- Static TEs</strong> <span class="math display">\[
Y_{it}(1)-Y_{it}(0) = \tau_i \qquad \forall\;t=1,\dots,T
\]</span> ::: Models with dynamics, will often normalize time relative to the period of treatment; sometimes referred to as event-time. For example, event-time <span class="math inline">\(s = -1\)</span> is the period just before treatment and <span class="math inline">\(s=0\)</span> the period of treatment.</p>
</section>
</section>
<section id="randomized-experiments" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="randomized-experiments"><span class="header-section-number">3</span> Randomized Experiments</h2>
<p>In Economics, randomized experiments are typically referred to as Randomized Control Trials (RCTs); a name borrowed from the Medical field. However, randomization is also used in lab experiments and does sometimes appear in real-world policies <span class="citation" data-cites="angrist1990lifetime">(see <a href="#ref-angrist1990lifetime" role="doc-biblioref">Angrist 1990</a>)</span>.</p>
<section id="selection" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="selection"><span class="header-section-number">3.1</span> Selection</h3>
<p>When comparing two groups, the difference between the mean of their outcomes can be decomposed into two terms: the ATT and a selection term.</p>
<p><span class="math display">\[
\begin{aligned}
&amp;E[Y_i|D_i =1]-E[Y_i|D_i=0] \\
=&amp;E[Y_i(1)|D_i =1]-[Y_i(0)|D_i =1]+E[Y_i(0)|D_i =1]-E[Y_i(0)|D_i=0] \\
=&amp;E[Y_i(1)-Y_i(0)|D_i=1] + E[Y_i(0)|D_i =1]-E[Y_i(0)|D_i=0]  \\
=&amp;ATT + \text{selection}
\end{aligned}
\]</span> where <span class="math inline">\(E[Y_i(0)|D_i =1]\)</span> is an unobserved counterfactual: the mean of the treated group had it not been treated.</p>
<p>Note, this is a particular definition of selection. When discussing the “problem of selection” in this literature, the question is whether:</p>
<p><span class="math display">\[
E[Y_i(0)|D_i =1]-E[Y_i(0)|D_i=0]\overset{?}{=}0
\]</span></p>
</section>
<section id="identification" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="identification"><span class="header-section-number">3.2</span> Identification</h3>
<p>Recall, under randomization assignment is unconfounded; therefore, the observed difference between the mean of the treatment and control group identifies,</p>
<p><span class="math display">\[
\begin{aligned}
&amp;E[Y_i|D_i =1]-E[Y_i|D_i=0] \\
=&amp;E[Y_i(1)|D_i =1]-E[Y_i(0)|D_i=0] \\
=&amp;E[Y_i(1)]-E[Y_i(0)] \\
=&amp;ATE
\end{aligned}
\]</span> where line 3 follows by unconfoundedness. This implies:</p>
<ol type="1">
<li><p>the selection term <span class="math inline">\(=0\)</span>;</p></li>
<li><p>the <span class="math inline">\(ATT = ATE = ATU\)</span>.</p></li>
</ol>
<p>An RCT can tell you about the ATE of the treatment, for the sampled population. It cannot tell you about the ATE for any unsampled population; an issue referred to as <em>external validity</em>.</p>
</section>
<section id="efficiency" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="efficiency"><span class="header-section-number">3.3</span> Efficiency</h3>
<p>One limitation of RCTs is their limited (sample) size. They can be expensive to run, thereby reducing the size of the treated and control sample. For this reason, researchers will take action to design the most efficient (powerful) experiment.</p>
<p>If <span class="math inline">\(N\)</span> (the sample size) is fixed, it is optimal (from an efficiency perspective) to assign <span class="math inline">\(N_t = 0.5 N\)</span> units to treatment.</p>
<p>A second action taken by researchers is to control for characteristics in a model; for example,</p>
<p><span class="math display">\[
  Y_i = \alpha + \beta D_i + X_i'\gamma + \upsilon_i
\]</span> In this instance, these regressors are not included for identification as treatment is unconfounded (this is not the case for stratified experiments; see below). Instead, they are there to reduce the residual variation of the error term.</p>
<p>It is important that these are <strong>good controls</strong>. The included covariates must not be potential outcomes of an experiment. In RCTs, you will typically see that researchers include covariates from a baseline survey.</p>
<p>The OLS estimator for <span class="math inline">\(\beta\)</span> from the above model is consistent, but may be biased in small-samples depending on whether the heterogeneity of the TE relates to the included <span class="math inline">\(X\)</span>’s <span class="citation" data-cites="deaton2010instruments">(<a href="#ref-deaton2010instruments" role="doc-biblioref">Deaton 2010</a>)</span>. <span class="math display">\[
p \lim \hat{\beta} = ATE
\]</span></p>
</section>
<section id="stratification" class="level3" data-number="3.4">
<h3 data-number="3.4" class="anchored" data-anchor-id="stratification"><span class="header-section-number">3.4</span> Stratification</h3>
<p>Many real-world RCTs stratify assignment into treatment. They divide the sample into blocks - typically based on observable characteristics - and assign each block into treatment independently. By implication, each group can be assigned into treatment with a different probability.</p>
<p>Stratification has an important advantage: since assignmet is unconfounded within each block (or conditional on the stratification covariates <span class="math inline">\(X_i\)</span>), you can conduct more efficient sub-sample analyses.</p>
<p>However, stratification also complicates the use of models to estimate TEs. Since, treatment is independent conditional on <span class="math inline">\(X_i\)</span>, you need to account for <span class="math inline">\(X_i\)</span> in the model.</p>
<p>Suppose, the statification variable(s) takes on <span class="math inline">\(m\)</span> distinct values: <span class="math inline">\(X_i\in\{x_1,x_2,\dots,x_m\}\)</span>. Then, the unconditional ATE can be written as a probablity weighted sum of conditional ATEs. <span class="math display">\[
ATE = \sum_{j=1}^m ATE(x_j)\cdot Pr(X_i=x_j)
\]</span> If you estimate a model, that conditions on each value of <span class="math inline">\(X_i\)</span> (referred to as ‘saturated controls’), the coefficient on the treatment indicator gives you a variance weighted average.</p>
<p><span class="math display">\[
Y_i = \beta D_i + \sum_{j=1}^{m}\gamma_j \mathbf{1}\{X_i = x_j\} + \zeta_i
\]</span> then,</p>
<p><span class="math display">\[
\beta = \frac{\sum_{j=1}^{m}ATE(x_j)Var(W_i|X_i=x_j)Pr(X_i=x_j)}{\sum_{l=1}^{m}Var(W_i|X_i=x_l)Pr(X_i=x_l)}
\]</span> where, <span class="math display">\[
Var(D_i|X_i) =Pr(D_i=1|X_i)\cdot \big(1-Pr(D_i=1|X_i)\big)
\]</span> Assigning treatment with different probabilities (based on <span class="math inline">\(X_i\)</span>), implies that the OLS estimator of a linear model with covariates will estimate a variance weighted estimand. If the ATE is independent of <span class="math inline">\(X_i\)</span>, this not a concern, since the weights still sum to 1.</p>
</section>
<section id="propensity-score" class="level3" data-number="3.5">
<h3 data-number="3.5" class="anchored" data-anchor-id="propensity-score"><span class="header-section-number">3.5</span> Propensity score</h3>
<p>In this literature, the probability of treatment (conditional on <span class="math inline">\(X_i\)</span>) is referred to as the propensity score:</p>
<p><span class="math display">\[
\rho(X_i) = Pr(D_i = 1|X_i)
\]</span> You can show that the unconditional ATE can be written as an (inverse) propensity weighted estimand:</p>
<p><span class="math display">\[
            E[Y_i(1)] = E\left[\frac{Y_i\cdot W_i}{\rho(X_i)}\right]
\]</span> and <span class="math display">\[
            E[Y_i(0)] = E\left[\frac{Y_i\cdot (1-D_i)}{1-\rho(X_i)}\right]
\]</span></p>
<p>Which means that,</p>
<p><span class="math display">\[
E[Y_i(1)-Y_i(0)] =E\left[\frac{Y_i\cdot D_i}{\rho(X_i)}-\frac{Y_i\cdot (1-D_i)}{1-\rho(X_i)}\right]= E\left[\frac{Y_i\cdot (D_i-\rho(X_i))}{\rho(X_i)\cdot(1-\rho(X_i))}\right]
\]</span></p>
<p>This Weighted Least Squares estimator for <span class="math inline">\(\beta\)</span> from the univariate model,</p>
<p><span class="math display">\[
Y_i = \alpha + \beta D_i + \varepsilon_i
\]</span> using weights,</p>
<p><span class="math display">\[
\lambda_i = \frac{1}{\rho(X_i)^{D_i}\cdot(1-\rho(X_i))^{1-D_i}}
\]</span> is an unbiased estimator for the unconditional ATE under stratified assignment. This referred to as the Horovitz-Thompson estimator.</p>
<p>This points to a wider issue within this literature: this approach to causal inference is built upon an experiment framework, which does not <em>necessarily</em> map to a (linear) regression-model econometrics framework.</p>
</section>
</section>
<section id="instrumental-variables" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="instrumental-variables"><span class="header-section-number">4</span> Instrumental Variables</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The following might be a slightly different presentation of instrumental variables to what you are used to from your undergraduate degree.</p>
</div>
</div>
<p>In some experiments, compliance - i.e.&nbsp;take-up of the treatment - is not a given. This could be for a number of reasons, including ethical reasons. In this case, assignment into the treatment-group does not gaurantee that the individual is treated.</p>
<p>Consider the RCT in <span class="citation" data-cites="banerjee2015miracle">Banerjee et al. (<a href="#ref-banerjee2015miracle" role="doc-biblioref">2015</a>)</span>. The authors randomly assigned a new micro-loan agency to a sub-sample of villages in India. It would be unethical to force a household to take on credit. Instead, the treatment randomly increased <em>access to</em> credit. In this application, the mean difference in <span class="math inline">\(Y_i\)</span> between the treatment and control villages cannot identify the causal impact of having a micro-loan. It identifies the ATE of living in a village with increased access to micro-loans.</p>
<p>In imperfect-compliance setting, we adopt the language of Intention to Treat (ITT) effects. In the words of the authors: “given the sampling frame, ours will be an intent-to-treat (ITT) analysis on a sample of “likely borrowers.” This is thus neither the effect on those who borrow nor the average effect on the neighborhood. Rather, it is the average effect of easier access to microfinance on those who are its primary targets.” <span class="citation" data-cites="banerjee2015miracle">(<a href="#ref-banerjee2015miracle" role="doc-biblioref">Banerjee et al. 2015, 35</a>)</span>.</p>
<p>You might be wondering, why can’t we just condition on receipt of the treatment? If compliance is imperfect, then take-up of the treatment is endogenous: determined by factors other than random assignment. As a result the treatment-receiving sample is no longer randomly assigned.</p>
<p>You can have both one-sided and two-sided non-compliance. Here, we will focus on the latter, as it more closely relates to the use of instruments in Applied Economics <span class="citation" data-cites="angrist1990lifetime">(for example <a href="#ref-angrist1990lifetime" role="doc-biblioref">Angrist 1990</a>)</span>. One-sided non-compliance means that some individuals in the treated group may not receive the treatment, but does not allow for the case where individuals in the control group may receive it. Two-sided non-compliance allows for both.</p>
<section id="compliance" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="compliance"><span class="header-section-number">4.1</span> Compliance</h3>
<p>Let <span class="math inline">\(D_i\in\{0,1\}\)</span> denote receipt of treatment and let <span class="math inline">\(Z_i\in\{0,1\}\)</span> denote treat-group assignment. With two-sided non-compliance, we can consider the potential outcomes of <span class="math inline">\(D_i\)</span>:</p>
<p><span class="math display">\[
D_i(Z_i)\in\{D_i(1),D_i(0)\}
\]</span></p>
<p>Using these potential outcomes we can assign names to each possible compliance status:</p>
<table class="caption-top table">
<caption>Compliance status:</caption>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(D_i(1) = 0\)</span></th>
<th><span class="math inline">\(D_i(1)=1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(D_i(0) = 0\)</span></td>
<td>never-treated (nt)</td>
<td>complier (c)</td>
</tr>
<tr class="even">
<td><span class="math inline">\(D_i(0) = 1\)</span></td>
<td>defier (d)</td>
<td>always-treated (at)</td>
</tr>
</tbody>
</table>
<p>Define <span class="math inline">\(G_i\in\{nt,c,d,at\}\)</span>, with <span class="math inline">\(Pr(G_i = g)\in\{\rho_{nt},\rho_c,\rho_d, \rho_{at}\}\)</span>.</p>
<p>When you look at the data, you don’t observe each potential outcome. Instead, you observe the pair <span class="math inline">\(\{Z_i,D_i\}\)</span>; each combination of which will contain a mix of the above groups.</p>
<table class="caption-top table">
<caption>Compliance status:</caption>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(D_i = 0\)</span></th>
<th><span class="math inline">\(D_i=1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(Z_i = 0\)</span></td>
<td>never-treated + compliers</td>
<td>always-treated + defiers</td>
</tr>
<tr class="even">
<td><span class="math inline">\(Z_i = 1\)</span></td>
<td>never-treated + defiers</td>
<td>always-treated + compliers</td>
</tr>
</tbody>
</table>
<p>The ITT of assignment on treatment receipt is given by:</p>
<p><span class="math display">\[
\begin{aligned}
ITT_D =&amp; E[D_i(1)-D_i(0)] \\
=&amp; E[D_i(1)]-E[D_i(0)] \\
=&amp; \rho_c + \rho_{at} - (\rho_d + \rho_{at}) \\
=&amp;\rho_c-\rho_d
\end{aligned}
\]</span></p>
<p>This is the difference in the proportion of compliers (those who take-up treatment only when assigned) and defiers (those who take up treatment only when not assigned) in the (super) population.</p>
<p>The potential outcomes for the outcome variable are:</p>
<p><span class="math display">\[
Y_i(Z_i,D_i(Z_i)) \in\{Y_i(0,0),Y_i(0,1),Y_i(1,0),Y_i(1,1)\}
\]</span></p>
<p>For example, <span class="math inline">\(Y_i(1,0)\)</span> is the potential outcome of unit <span class="math inline">\(i\)</span> were they to receive assignment into treatment, but not take it up. Likewise, <span class="math inline">\(Y_i(1,1)\)</span> represents the potential outcome of unit <span class="math inline">\(i\)</span> were they to take-up the treatment after being assigned it.</p>
<p>The ITT of assignment on the main outcome is:</p>
<p><span class="math display">\[
ITT_Y = E[Y_i(1)-Y_i(0)] = E[Y_i(1,D_i(1))-Y_i(0,D_i(0))]
\]</span></p>
<p>This term is what you identify when comparing the means of the outcome in the treated and control groups, under randomization.</p>
<p>Under randomization, the instrument is unconfounded with respect to both sets of potential outcomes:</p>
<p><span class="math display">\[
Z_i \perp D_i(1),D_i(0),Y_i(0,0),Y_i(0,1),Y_i(1,0),Y_i(1,1)
\]</span></p>
</section>
<section id="identification-1" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="identification-1"><span class="header-section-number">4.2</span> Identification</h3>
<p>In addition to unconfoundedness, we require the following exclusion restrictions assumptions:</p>
<ul>
<li><p>for all never-takers: <span class="math inline">\(Y_i(1,0)=Y_i(0,0)\)</span></p></li>
<li><p>for all always-takers: <span class="math inline">\(Y_i(0,1)=Y_i(1,1)\)</span></p></li>
</ul>
<p>Then we need a final <strong>monotonicity</strong> (i.e., no defiers) assumption:</p>
<ul>
<li>no defiers: <span class="math inline">\(D_i(1)\geq D_i(0)\Rightarrow \rho_d = 0\)</span></li>
</ul>
<p>Under these four assumptions:</p>
<p><span class="math display">\[
  \frac{ITT_Y}{ITT_D} = E[Y_i(1)-Y_i(0)|G_i = c ] = LATE
\]</span> This is referred to as the Local Average Treatment Effect: the ATE of compliers. Note, you cannot directly observe the population of compliers in the data, as this would require observing both states of the outcome <span class="math inline">\(D_i(Z_i)\)</span>. In contrast, when we identify the ATT (as with DiD), this the ATE of the observed Treated population.</p>
<p>We can prove this result as follows. In the denominator, we have:</p>
<p><span class="math display">\[
\begin{aligned}
E[D_i(1)-D_i(0)] =&amp; \rho_{nt} E[D_i(1)-D_i(0)|G_i=nt] \\
&amp;+\rho_{at} E[D_i(1)-D_i(0)|G_i=at] \\
&amp;+\rho_{c} E[D_i(1)-D_i(0)|G_i=c] \\
=&amp;\rho_c
\end{aligned}
\]</span> since by the monotonicity (no defiers) assumption <span class="math inline">\(\rho_d=0\)</span>; <span class="math inline">\(D_i(1)=D_i(0)\)</span> for never- and always-takers; and <span class="math inline">\(D_i(1) - D_i(0)=1\)</span> for compliers.</p>
<p>In the numerator, we have:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;E[Y_i(1,D_i(1))-Y_i(0,D_i(0))] \\
=&amp; E[Y_i(1,1)|D_i(1)=1]\cdot Pr(D_i(1)=1) + E[Y_i(1,0)|D_i(1)=0]\cdot Pr(D_i(1)=0) \\
&amp;- E[Y_i(0,1)|D_i(0)=1]\cdot Pr(D_i(0)=1) - E[Y_i(0,0)|D_i(0)=0]\cdot Pr(D_i(0)=0) \\
\end{aligned}
\]</span> Assuming no defiers, <span class="math display">\[
\begin{aligned}
E[Y_i(0,1)|D_i(0)=1]\cdot Pr(D_i(0)=1) =&amp;\rho_{at}E[Y_i(0,1)|G_i=at] \\
=&amp;\rho_{at}E[Y_i(1,1)|G_i=at]
\end{aligned}
\]</span> Where the last line follows from the exclusion restriction. Similarly,<br>
<span class="math display">\[
\begin{aligned}
E[Y_i(1,0)|D_i(1)=0]\cdot Pr(D_i(1)=0) =&amp;\rho_{nt}E[Y_i(1,0)|G_i=nt] \\
=&amp;\rho_{nt}E[Y_i(0,0)|G_i=nt]
\end{aligned}
\]</span> Applying the exclusion restrictions we get:</p>
<p><span class="math display">\[
\begin{aligned}
=&amp; \rho_c E[Y_i(1,1)|G_i=c]- \rho_c E[Y_i(0,0)|G_i = c] \\
&amp;+ \rho_{at} E[Y_i(1,1)|G_i=at]- \rho_{at}E[Y_i(1,1)|G_i=at]\\
&amp;+\rho_{nt}E[Y_i(0,0)|G_i=nt]-\rho_{nt}E[Y_i(0,0)|G_i=nt] \\
=&amp;\rho_c E[Y_i(1,1)-Y_i(0,0)|G_i=c]  \\
\end{aligned}
\]</span> Dividing by the <span class="math inline">\(ITT_D\)</span>, we get the LATE result.</p>
</section>
<section id="estimation" class="level3" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="estimation"><span class="header-section-number">4.3</span> Estimation</h3>
<p>The LATE can be estimated by two-stage-least-squares (2SLS).</p>
<ol type="1">
<li>First, estimate the first-stage (<span class="math inline">\(ITT_D\)</span>):</li>
</ol>
<p><span class="math display">\[
D = \phi_1 + \phi_2 Z + \nu
\]</span></p>
<ol start="2" type="1">
<li>Second, estimate the second-stage, substituting <span class="math inline">\(D\)</span> with the predicted values of the first-stage:<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></li>
</ol>
<p><span class="math display">\[
Y = \beta_1 + \beta_2 P_ZD + \epsilon
\]</span> In this just-identified case,</p>
<p><span class="math display">\[
    \hat{\beta}^{2SLS}_2 = \frac{\hat{\gamma}_2}{\hat{\phi}_2}
\]</span> where <span class="math inline">\(\hat{\gamma}_2\)</span> is the OLS estimator of the reduced form equation,</p>
<p><span class="math display">\[
Y = \gamma_1 + \gamma_2 Z + \zeta
\]</span> Recall, the reduced form equation identifies the <span class="math inline">\(ITT_Y\)</span>.</p>
</section>
<section id="reduced-form" class="level3" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="reduced-form"><span class="header-section-number">4.4</span> Reduced form</h3>
<p>Recall, <span class="math inline">\(Z\)</span> denotes random treatment-assignment. Much of empirical in applied microeconomics takes on this form: regressing the outcome directly on treatment-assignment. It is for this reason that it is often referred to as “reduced form” research.</p>
<p>However, the phrase “reduced form” comes from an older literature, where the regression of <span class="math inline">\(Y\)</span> on <span class="math inline">\(D\)</span>, where <span class="math inline">\(D\)</span> was potentially endogenous, was a “structural equation”, including parameters from a structural model. In this setting, we do not typically adopt this phrase to describe the relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(D\)</span>.</p>
<p>This framework provides a useful perspective on experiments. Instruments are central to the way economists think about causation <span class="citation" data-cites="angrist2001instrumental">(see <a href="#ref-angrist2001instrumental" role="doc-biblioref">Angrist and Krueger 2001</a>)</span>, and randomized experiments provide the ideal instrumental variable. You can either examine the reduced-form relationship, given by treatment-assignment, or use the experiment as an instrument to study an endogenous relationship.</p>
<p>Consider the following setting. Suppose, you are interested in the causal relationship between household income (RHS) and investment into child-education (LHS) in poorer countries. Evidently household income (a continuous variable) is endogenous, and comparing households with high and low incomes will give rise to differences largely explained by selection.</p>
<p>We need a source of exogenous variation in household income. We could design a RCT that enrolls a random sample of households into a universal basic income (UBI) scheme. Comparing the difference in education of households in treatment and control, would give us the reduced form effect of the experiment. Alternatively, we could use treatment assignment as an instrument for household income. Of course, we hope to find that treatment increases household income by an amount close to the value of the UBI scheme.</p>
</section>
</section>
<section id="observational-studies" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="observational-studies"><span class="header-section-number">5</span> Observational Studies</h2>
<p>In observational studies, the functional form of the assignment mechanism is not known. The standard approach in these settings is to assume Conditional Independence (CIA/unconfoundedness). Afterall, “[w]ithout unconfoundedness, there is no general approach to estimating treatment effects” (Imbens and Wooldridge, 2009, p.7).</p>
<p><span class="math display">\[
Y_i(1),Y_i(0)\perp D_i|X_i
\]</span> This assumption suggests that <em>conditional on <span class="math inline">\(X\)</span></em> it is <em>as if</em> assignment is randomized. Thus,</p>
<p><span class="math display">\[
E[Y_i(0)|D_i=1,X_i]-E[Y_i(0)|D_i=0,X_i] = 0
\]</span> There is no selection, conditional on <span class="math inline">\(X_i\)</span>. The above statement, is also referred to as “selection on observables”. The treatment and control group can differ in terms of the distribution of <span class="math inline">\(X_i\)</span>; however, conditional on <span class="math inline">\(X_i\)</span> they are balanced. This rules out “selection on unobservables”.</p>
<section id="common-support" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="common-support"><span class="header-section-number">5.1</span> Common support</h3>
<p>In controlled experiments the researcher picks the number of treated and control units. There is just one requirement: <span class="math inline">\(1\leq N_t \leq N-1\)</span>, at least one unit must be (un)treated. In observational studies, you do not have direct control over the assignment mechanism. We therefore need an additional assumption: <strong>common support</strong> (or overlap).</p>
<div id="def-overlap" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3</strong></span> <strong>- Common Support</strong> <span class="math display">\[
0&lt; \rho(X_i) &lt; 1
\]</span></p>
</div>
<p>This assumption ensures that for every <span class="math inline">\(X_i\)</span>, you observe both treated and control units with a non-zero probability.</p>
</section>
<section id="matching" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="matching"><span class="header-section-number">5.2</span> Matching</h3>
<p>The most direct approach to matching is covariate-matching: given common support, you can estimate a Conditional ATE for each <span class="math inline">\(X_i\)</span>, after which you aggregate up to the unconditional ATE using the distribution of <span class="math inline">\(X\)</span>. <span class="math display">\[
ATE = \sum_{j=1}^m ATE(x_j)\cdot Pr(X_i=x_j)
\]</span> Unfortunately, covariate matching quickly encounters the <strong>curse of dimensionality</strong>. You need to match on all possible values of the vector <span class="math inline">\(X_i\in\mathbb{R}^k\)</span>. Consider, if each of the <span class="math inline">\(X_{ik}\)</span> covariates is a dummy variable, then the number of possible values for the vector <span class="math inline">\(X_i\)</span> is <span class="math inline">\(2^k\)</span>.</p>
<p>In addition, there is the challenge of matching on continuous variables. This can be solved by discretizing the support of the continuous variable, but necessarily increases the number of values to matching on.</p>
<p>An alternative is Propensity Score Matching (PSM). <span class="citation" data-cites="rosenbaum1983central">Rosenbaum and Rubin (<a href="#ref-rosenbaum1983central" role="doc-biblioref">1983</a>)</span> show that you can match on the propensity score instead of covariates. This is because the propensity score is a balancing score.</p>
<div id="def-balance" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4</strong></span> <strong>- Balancing Score</strong>: A function <span class="math inline">\(b:\mathbb{R}^k\rightarrow\mathbb{R}\)</span>, such that, <span class="math display">\[
  D_i\perp X_i | b(X_i)
\]</span></p>
</div>
<p>You can show that <span class="math inline">\(\rho(X_i)=Pr(D_i=1|X_i)\)</span> is a balancing score, by demonstrating the equality between: <span class="math display">\[
Pr(D_i=1|X_i,\rho(X_i)) = Pr(D_i=1|\rho(X_i))
\]</span> Given this result, unconfoundedness implies unconfoundedness <em>on the propensity score</em>, <span class="math display">\[
Y_i(1),Y_i(0)\perp D_i|\rho(X_i)
\]</span> Take a look at <span class="citation" data-cites="hirano2003efficient">Hirano, Imbens, and Ridder (<a href="#ref-hirano2003efficient" role="doc-biblioref">2003</a>)</span> and <span class="citation" data-cites="caliendo2008some">Caliendo and Kopeinig (<a href="#ref-caliendo2008some" role="doc-biblioref">2008</a>)</span>, if you are interested in some of the practicialities of PSM estimation. The major challenge for PSM, in observational study settings, is that we do not know the true functional form of <span class="math inline">\(\rho(X_i)\)</span>.</p>
</section>
<section id="regression" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="regression"><span class="header-section-number">5.3</span> Regression</h3>
<p>You can think of linear regression as a matching estimator. Recall, we can always write:</p>
<p><span class="math display">\[
Y_i = E[Y_i|D_i,X_i]+\varepsilon_i
\]</span> where <span class="math inline">\(E[\varepsilon_i|D_i,X_i]=0\)</span>. Given that <span class="math inline">\(Y_i\)</span> is a combination of potential outcomes,</p>
<p><span class="math display">\[
Y_i = E[Y_i(0)|D_i,X_i]+D_iE[Y_i(1)-Y_i(0)|D_i,X_i]+\varepsilon_i
\]</span> Assuming CIA/unconfoundedness, <span class="math display">\[
Y_i = E[Y_i(0)|X_i]+D_iE[Y_i(1)-Y_i(0)|X_i]+\varepsilon_i
\]</span> If we are willing to assuming that <span class="math inline">\(E[Y_i(0)|X_i]\)</span> is linear (in parameters), then we get <span class="math display">\[
Y_i = X_i'\gamma+D_iE[Y_i(1)-Y_i(0)|X_i]+\varepsilon_i
\]</span> We then need to make an assumption concerning the heterogeneity w.r.t. <span class="math inline">\(X\)</span>. Alternatively, we can opt for a more flexible saturated-controls model, <span class="math display">\[
Y_i = \sum_{j=1}^{m}\gamma_j \mathbf{1}\{X_i = x_j\}+D_iE[Y_i(1)-Y_i(0)|X_i]+\zeta_i
\]</span> Clearly, we need to make an assumption concerning how heteroegeneity relates to <span class="math inline">\(X_i\)</span>. If it is independent of <span class="math inline">\(X_i\)</span>, then the saturated model will approximate any functional form of <span class="math inline">\(E[Y_i(0)|X_i]\)</span>, but is limited by the curse of dimensionality.</p>
<p>Suppose we are unwilling to assume homogeneity w.r.t. <span class="math inline">\(X\)</span>. If we allow the coefficient on <span class="math inline">\(D\)</span> to vary with every value of <span class="math inline">\(X\)</span>, we are back to covariate-matching (i.e.&nbsp;a separate model for each covariate value). If we estimate a single parameter coefficient for <span class="math inline">\(D\)</span>, we end up with variance weighting. There is no obvious path forward.</p>
<p>We also need to take note of common-support. Saturated-controls models require common-support, but linear models do not. You should be aware that linear models can allow you to extrapolate a counterfactual to parts of the data without common support.</p>
</section>
</section>
<section id="difference-in-differences" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="difference-in-differences"><span class="header-section-number">6</span> Difference-in-Differences</h2>
<p>Difference-in-differences (DiD) is one of the most commonly used empirical strategies in applied microeconomics research. This is partly because the method is well suited to the study of “natural”/quasi-experiments. These are empirical settings where the conditions of an experiment are met - that is, assignment into a treatment and control group - but the researcher has no control over the assignment. For example, a natural disaster that shocks a particular region, but does not affect a neighbouring region <span class="citation" data-cites="card1990impact">(see <a href="#ref-card1990impact" role="doc-biblioref">Card 1990</a>)</span>. Or, the introduction of a new policy that affects one group of people, but not another.</p>
<p>Crucially, DiD does <em>not</em> require unconfoundedness. Instead, identification is based on a parallel trends assumption, as well as a few exclusion restrictions. The DiD approach utilizes a time-dimesion that has so far been ignored. It also has the advantage of being feasible with repeated cross-sections of data, as panel data is not always avaiable.</p>
<section id="group-2-period" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="group-2-period"><span class="header-section-number">6.1</span> 2-group-2-period</h3>
<p>The simple 2-group-2-period DiD set-up has the following characteristics,</p>
<ul>
<li>treatment takes place in period <span class="math inline">\(t_0\)</span>;</li>
<li>you observe both treated and control samples in a period before and after treatment;</li>
<li>and there exists a never-treated control group.</li>
</ul>
<p>As before, let the time-invariant dummy variable, <span class="math inline">\(D_i\)</span>, denote the treatment-group status of unit <span class="math inline">\(i\)</span>. Next, let the time-varying dummy variable, <span class="math inline">\(T_t=\mathbf{1}\{t\geq t_0\}\)</span>, be <span class="math inline">\(=1\)</span> in the period of treatment (<span class="math inline">\(t_0\)</span>) and <span class="math inline">\(0\)</span> before.</p>
<p>We will make the following exclusion restrictions,</p>
<div id="def-noant" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 5</strong></span> <strong>- Exclusion Restriction</strong>: No Anticipation (no pre-emptive behaviour) <span class="math display">\[
Y_{it} = Y_{it}(1) = Y_it(0)   \qquad\forall\; (i,t)\;\text{s.t. }\;t&lt; t_0
\]</span></p>
</div>
<p>Some texts will assume random/unexpected timing of the treatment, as a mechanism that rules out anticipation. Note, this assumption is stronger than what is required for identification of the ATT. For example, <span class="citation" data-cites="wooldridge2023simple">Wooldridge (<a href="#ref-wooldridge2023simple" role="doc-biblioref">2023</a>)</span> assumes the a weaker assumption:</p>
<p><span class="math display">\[
E[Y_{it}(1)|D_i=1,T_t=0] = E[Y_{it}(0)|D_i=1,T_t=0]
\]</span></p>
<div id="def-spill" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 6</strong></span> <strong>- Exclusion Restriction</strong>: No Spillovers <span class="math display">\[
Y_{it}=Y_{it}(0)   \qquad \forall \;(i,t) \;\text{s.t.}\;D_i=0
\]</span></p>
</div>
<p>Evidently, this assumption is met by SUTVA.</p>
<p>Then, we can write the observed <span class="math inline">\(Y_{it}\)</span> as, <span class="math display">\[
    \begin{aligned}
        Y_{it} =&amp; \begin{cases}
             Y_{it}(0) \qquad\forall\quad t&lt;t_0 \\
            Y_{it}(0) + D_i\cdot(Y_{it}(1)-Y_{it}(0))  \qquad\forall\quad t\geq t_0
        \end{cases} \\
        =&amp;Y_{it}(0) + T_t\cdot D_i\cdot(Y_{it}(1)-Y_{it}(0))
    \end{aligned}
\]</span></p>
</section>
<section id="parallel-trends" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="parallel-trends"><span class="header-section-number">6.2</span> Parallel trends</h3>
<p>The main identifying assumption of a DiD model is parallel trends. This can be stated as,</p>
<div id="def-ptrends" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 7</strong></span> <strong>- Parallel Trends</strong> <span class="math display">\[
\begin{aligned}
                &amp;E[Y_{it}(0)|D_i=0,T_t=1]-E[Y_{it}(0)|D_i=0,T_t=0] \\
                =&amp;E[Y_{it}(0)|D_i=1,T_t=1]-E[Y_{it}(0)|D_i=1,T_t=0]
            \end{aligned}
\]</span></p>
</div>
<p>Under these assumptions, the difference-in-differences (DiD) of conditional means gives you the ATT.<br>
<span class="math display">\[
\begin{aligned}
            &amp;\big[E[Y_{it}|D_i=1,T_t=1]-E[Y_{it}|D_i=1,T_t=0]\big]\\
            &amp;-\big[E[Y_{it}|D_i=0,T_t=1]-E[Y_{it}|D_i=0,T_t=0]\big] \\
            =&amp;\big[E[Y_{it}(1)|D_i=1,T_t=1]-E[Y_{it}(0)|D_i=1,T_t=0]\big] \\
            &amp;-\big[E[Y_{it}(0)|D_i=0,T_t=1]-E[Y_{it}(0)|D_i=0,T_t=0]\big] \\
            =&amp;\big[E[Y_{it}(1)|D_i=1,T_t=1]-E[Y_{it}(0)|D_i=1,T_t=1]\big] \\
            &amp;+\big[E[Y_{it}(0)|D_i=1,T_t=1]-E[Y_{it}(0)|D_i=1,T_t=0]\big] \\
            &amp;-\big[E[Y_{it}(0)|D_i=0,T_t=1]-E[Y_{it}(0)|D_i=0,T_t=0]\big] \\
            =&amp;E[Y_{it}(1)-Y_{it}(0)|D_i=1,T_t=1]\\
            =&amp;ATT(t_0)
        \end{aligned}
\]</span> Where, parallel trends implies that the difference between the last two parentheses in line 3 is 0. Note, I have denoted this as the ATT in period <span class="math inline">\(t_0\)</span> as the treatment effect may not be static.</p>
</section>
<section id="regression-1" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="regression-1"><span class="header-section-number">6.3</span> Regression</h3>
<p>This DiD estimand can be expressed within a linear regression model,</p>
<p><span class="math display">\[
Y_{it} = \alpha + \psi D_i + \delta T_t + \beta D_i\times T_t + \varepsilon_i
\]</span> where <span class="math inline">\(\beta\)</span>, the parameter on the interaction term is given by the above DiD.</p>
<p>In the above model, the <span class="math inline">\(E[\varepsilon_i|D_i,T_t]=0\)</span>, since the model is fully saturated. However, this does not mean that the <span class="math inline">\(\beta=ATT\)</span>, it just means that <span class="math inline">\(\beta\)</span> gives you the DiD of conditional means and the OLS estimator, <span class="math inline">\(\hat{\beta}^{DD}\)</span>, is an unbiased estimator. The fact that <span class="math inline">\(\beta=ATT\)</span> depends on the parallel trends assumption, stated in terms of the potential outcome <span class="math inline">\(Y_{it}(0)\)</span>. This is a perfect example of how identification of (population) parameters within a regression model is different to identification of TEs.</p>
<p>Given this linear regression model, some texts will state the parallel trends in parametric form as:</p>
<div id="def-ptrends2" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 8</strong></span> <strong>- Parallel Trends (parametric version)</strong> <span class="math display">\[
                E[Y_{it}(0)|D_i=0,T_t=1]=\alpha + \psi D_i + \delta T_t
\]</span></p>
</div>
<p>The two definitions are equivalent, if you consider the definition of the parameters in the above expression.</p>
<p>The above specification does not require longitudinal data; however, if it is available you can then estimate the Fixed Effects model:</p>
<p><span class="math display">\[
Y_{it} = \alpha_i + \delta T_t + \beta D_i\times T_t + \varepsilon_i
\]</span> Controlling for unit-FEs tends to yield a more efficient estimator, as the unit-level dummies explain more of the variation in <span class="math inline">\(Y\)</span>. Moreover, with a balanced panel, you can show:</p>
<p><span class="math display">\[
\hat{\beta}^{LSDV} = \hat{\beta}^{DD}
\]</span> The result arises from the fact that the regressors in the simple DiD model provide the same projection of the interaction term as the FE model which replaces the constant and <span class="math inline">\(D\)</span>-dummy with unit-specific dummy variables.</p>
</section>
<section id="group-multi-period" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="group-multi-period"><span class="header-section-number">6.4</span> 2-group-multi-period</h3>
<p>We can extend the above set-up to include multiple periods, before and after the treatment. We do then need to add an assumption that the treatment is absorbing (or ‘always-on’). We can also now allow for dynamic TEs.</p>
<p>With multiple periods, the above specification (including regressors <span class="math inline">\([1,D,T,D\times T]\)</span>) is referred to as a ‘static’ specification. This is because it estimates a single ATT for all post-treatment periods; as would be appropriate if the TE is indeed static.</p>
<p>It is preferable to estimate one of the following dynamic specifications:</p>
<ul>
<li><p>semi-dynamic specification <span class="math display">\[
Y_{it} = \psi D_i + \delta_t + \sum_{j\geq t_0} \beta_j D_i\times \mathbf{1}\{t=j\} + \varepsilon_i
\]</span> or with panel data, <span class="math display">\[
Y_{it} = \alpha_i + \delta_t + \sum_{j\geq t_0} \beta_j D_i\times \mathbf{1}\{t=j\} + \upsilon_i
\]</span></p></li>
<li><p>fully-dynamic specification <span class="math display">\[
Y_{it} = \psi D_i + \delta_t + \sum_{j\neq t_0-k} \beta_j D_i\times \mathbf{1}\{t=j\} + \varepsilon_i
\]</span> or with panel data, <span class="math display">\[
Y_{it} = \alpha_i + \delta_t + \sum_{j\neq t_0-k} \beta_j D_i\times \mathbf{1}\{t=j\} + \upsilon_i
\]</span></p></li>
</ul>
<p>for a chosen base period (in the pre-period): <span class="math inline">\(k\geq 1\)</span>.</p>
<p>The fully-dynamic specification is preferred for the following reason. The pre-treatment <span class="math inline">\(\beta_j\)</span> coefficients (<span class="math inline">\(j&lt;t_0\)</span>), provide a valid test for parallel trends <strong>in the pre-period</strong>. This can be used to <em>support</em> the assumption of parallel trends in the post-period. Note, this is NOT a test of parallel trends in the post-period when it needs to hold.</p>
<p>Suppose <span class="math inline">\(k=1\)</span>, then the base period is <span class="math inline">\(t_0-1\)</span>. Assuming no anticipation, we can then write <span class="math inline">\(\beta_{t_0-2}\)</span> as,</p>
<p><span class="math display">\[
\begin{aligned}
            \beta_{t_0-2} =&amp; \big[E[Y_{it}|D_i=1,t=t_0-2]-E[Y_{it}|D_i=1,t=t_0-1]\big]\\
            &amp;-\big[E[Y_{it}|D_i=0,t=t_0-2]-E[Y_{it}|D_i=0,t=t_0-1]\big] \\
            =&amp;\big[E[Y_{it}(0)|D_i=1,t=t_0-2]-E[Y_{it}(0)|D_i=1,t=t_0-1]\big] \\
            &amp;-\big[E[Y_{it}(0)|D_i=0,t=t_0-2]-E[Y_{it}(0)|D_i=0,t=t_0-1]\big]
        \end{aligned}
\]</span> The test, <span class="math inline">\(H_0:\beta_{t_0-2}=0\)</span> is a valid test for parallel trends between period <span class="math inline">\(t_0-2\)</span> and <span class="math inline">\(t_0-1\)</span> (assuming no anticipation).</p>
<p>Suppose <span class="math inline">\(k=2\)</span>, then the base period is <span class="math inline">\(t_0-2\)</span>. Assuming parallel trends, we can then write <span class="math inline">\(\beta_{t_0-1}\)</span> as,</p>
<p><span class="math display">\[
\begin{aligned}
            \beta_{t_0-1} =&amp; \big[E[Y_{it}|D_i=1,t=t_0-1]-E[Y_{it}|D_i=1,t=t_0-2]\big]\\
            &amp;-\big[E[Y_{it}|D_i=0,t=t_0-1]-E[Y_{it}|D_i=0,t=t_0-2]\big] \\
            =&amp;\big[E[Y_{it}(1)-Y_{it}(0)|D_i=1,t=t_0-1] \\
            =&amp;ATT(t_0-1)
        \end{aligned}
\]</span> The test, <span class="math inline">\(H_0:\beta_{t_0-1}=0\)</span> is a valid test for no anticipation in period <span class="math inline">\(t_0-1\)</span> (assuming parallel trends). Crucially, in both instances, we must assume one assumption to test the other. That is, you cannot disentangle a pre-emptive behaviour from a failure of parallel trends in the data.</p>
</section>
<section id="further-reading" class="level3" data-number="6.5">
<h3 data-number="6.5" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">6.5</span> Further reading</h3>
<p>There is a large body of literature that discusses a range of topics related to DiD models. Two topics you should take note of when applying these methods are: the appropriate estimation of SEs, and heterogeneity in staggered DiDs (also referred to as event-studies). I have provided a few citations below.</p>
<p>Take a look at the following texts concerning clustered SEs within DiD models:</p>
<ul>
<li><span class="citation" data-cites="wooldridge2003cluster">Wooldridge (<a href="#ref-wooldridge2003cluster" role="doc-biblioref">2003</a>)</span></li>
<li><span class="citation" data-cites="bertrand2004much">Bertrand, Duflo, and Mullainathan (<a href="#ref-bertrand2004much" role="doc-biblioref">2004</a>)</span></li>
<li><span class="citation" data-cites="abadie2023should">Abadie et al. (<a href="#ref-abadie2023should" role="doc-biblioref">2023</a>)</span></li>
</ul>
<p>Take a look at the following texts to learn more about staggered DiD (event-study) models:</p>
<ul>
<li><span class="citation" data-cites="imai2019should">Imai and Kim (<a href="#ref-imai2019should" role="doc-biblioref">2019</a>)</span></li>
<li><span class="citation" data-cites="de2020two">Clément De Chaisemartin and D’Haultfœuille (<a href="#ref-de2020two" role="doc-biblioref">2020</a>)</span>; <span class="citation" data-cites="de2023two">Clement De Chaisemartin and D’Haultfœuille (<a href="#ref-de2023two" role="doc-biblioref">2023</a>)</span>; and <span class="citation" data-cites="de2023twosurvey">Clément De Chaisemartin and D’Haultfœuille (<a href="#ref-de2023twosurvey" role="doc-biblioref">2023</a>)</span></li>
<li><span class="citation" data-cites="sun2021estimating">Sun and Abraham (<a href="#ref-sun2021estimating" role="doc-biblioref">2021</a>)</span> (see also Stata package <code>eventstudyweights</code> and <code>eventstudyinteract</code>)</li>
<li><span class="citation" data-cites="callaway2021difference">Callaway and Sant’Anna (<a href="#ref-callaway2021difference" role="doc-biblioref">2021</a>)</span> (see also Stata package <code>csdid</code> and <code>drdid</code>)</li>
<li><span class="citation" data-cites="goodman2021difference">Goodman-Bacon (<a href="#ref-goodman2021difference" role="doc-biblioref">2021</a>)</span></li>
<li><span class="citation" data-cites="athey2022design">Athey and Imbens (<a href="#ref-athey2022design" role="doc-biblioref">2022</a>)</span></li>
<li><span class="citation" data-cites="borusyak2024revisiting">Borusyak, Jaravel, and Spiess (<a href="#ref-borusyak2024revisiting" role="doc-biblioref">2024</a>)</span></li>
</ul>
<p>Take a look at the following texts to learn more about parallel trends for non-linear models:</p>
<ul>
<li><span class="citation" data-cites="wooldridge2023simple">Wooldridge (<a href="#ref-wooldridge2023simple" role="doc-biblioref">2023</a>)</span></li>
</ul>
<p>Take a look at the following texts to learn more about conditional parallel trends:</p>
<ul>
<li><span class="citation" data-cites="caetano2024difference">Caetano and Callaway (<a href="#ref-caetano2024difference" role="doc-biblioref">2024</a>)</span></li>
</ul>
</section>
</section>
<section id="references" class="level2" data-number="7">




</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">7 References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-abadie2023should" class="csl-entry" role="listitem">
Abadie, Alberto, Susan Athey, Guido W Imbens, and Jeffrey M Wooldridge. 2023. <span>“When Should You Adjust Standard Errors for Clustering?”</span> <em>The Quarterly Journal of Economics</em> 138 (1): 1–35.
</div>
<div id="ref-angrist1990lifetime" class="csl-entry" role="listitem">
Angrist, Joshua D. 1990. <span>“Lifetime Earnings and the Vietnam Era Draft Lottery: Evidence from Social Security Administrative Records.”</span> <em>The American Economic Review</em>, 313–36.
</div>
<div id="ref-angrist2014mastering" class="csl-entry" role="listitem">
———. 2014. <em>Mastering’metrics: The Path from Cause to Effect</em>. Princeton University Press.
</div>
<div id="ref-angrist2001instrumental" class="csl-entry" role="listitem">
Angrist, Joshua D, and Alan B Krueger. 2001. <span>“Instrumental Variables and the Search for Identification: From Supply and Demand to Natural Experiments.”</span> <em>Journal of Economic Perspectives</em> 15 (4): 69–85.
</div>
<div id="ref-angrist2009" class="csl-entry" role="listitem">
Angrist, Joshua D, and Jörn-Steffen Pischke. 2009. <em>Mostly Harmless Econometrics: An Empiricist’s Companion</em>. Princeton university press.
</div>
<div id="ref-angrist2010credibility" class="csl-entry" role="listitem">
———. 2010. <span>“The Credibility Revolution in Empirical Economics: How Better Research Design Is Taking the Con Out of Econometrics.”</span> <em>Journal of Economic Perspectives</em> 24 (2): 3–30.
</div>
<div id="ref-athey2017state" class="csl-entry" role="listitem">
Athey, Susan, and Guido W Imbens. 2017. <span>“The State of Applied Econometrics: Causality and Policy Evaluation.”</span> <em>Journal of Economic Perspectives</em> 31 (2): 3–32.
</div>
<div id="ref-athey2022design" class="csl-entry" role="listitem">
———. 2022. <span>“Design-Based Analysis in Difference-in-Differences Settings with Staggered Adoption.”</span> <em>Journal of Econometrics</em> 226 (1): 62–79.
</div>
<div id="ref-banerjee2015miracle" class="csl-entry" role="listitem">
Banerjee, Abhijit, Esther Duflo, Rachel Glennerster, and Cynthia Kinnan. 2015. <span>“The Miracle of Microfinance? Evidence from a Randomized Evaluation.”</span> <em>American Economic Journal: Applied Economics</em> 7 (1): 22–53.
</div>
<div id="ref-bertrand2004much" class="csl-entry" role="listitem">
Bertrand, Marianne, Esther Duflo, and Sendhil Mullainathan. 2004. <span>“How Much Should We Trust Differences-in-Differences Estimates?”</span> <em>The Quarterly Journal of Economics</em> 119 (1): 249–75.
</div>
<div id="ref-borusyak2024revisiting" class="csl-entry" role="listitem">
Borusyak, Kirill, Xavier Jaravel, and Jann Spiess. 2024. <span>“Revisiting Event-Study Designs: Robust and Efficient Estimation.”</span> <em>Review of Economic Studies</em>, rdae007.
</div>
<div id="ref-caetano2024difference" class="csl-entry" role="listitem">
Caetano, Carolina, and Brantly Callaway. 2024. <span>“Difference-in-Differences When Parallel Trends Holds Conditional on Covariates.”</span> <em>arXiv Preprint arXiv:2406.15288</em>.
</div>
<div id="ref-caliendo2008some" class="csl-entry" role="listitem">
Caliendo, Marco, and Sabine Kopeinig. 2008. <span>“Some Practical Guidance for the Implementation of Propensity Score Matching.”</span> <em>Journal of Economic Surveys</em> 22 (1): 31–72.
</div>
<div id="ref-callaway2021difference" class="csl-entry" role="listitem">
Callaway, Brantly, and Pedro HC Sant’Anna. 2021. <span>“Difference-in-Differences with Multiple Time Periods.”</span> <em>Journal of Econometrics</em> 225 (2): 200–230.
</div>
<div id="ref-cameron2005" class="csl-entry" role="listitem">
Cameron, A Colin, and Pravin K Trivedi. 2005. <em>Microeconometrics: Methods and Applications</em>. Cambridge university press.
</div>
<div id="ref-card1990impact" class="csl-entry" role="listitem">
Card, David. 1990. <span>“The Impact of the Mariel Boatlift on the Miami Labor Market.”</span> <em>Ilr Review</em> 43 (2): 245–57.
</div>
<div id="ref-cunningham2021causal" class="csl-entry" role="listitem">
Cunningham, Scott. 2021. <em>Causal Inference: The Mixtape</em>. Yale university press.
</div>
<div id="ref-de2023two" class="csl-entry" role="listitem">
De Chaisemartin, Clement, and Xavier D’Haultfœuille. 2023. <span>“Two-Way Fixed Effects and Differences-in-Differences Estimators with Several Treatments.”</span> <em>Journal of Econometrics</em> 236 (2): 105480.
</div>
<div id="ref-de2020two" class="csl-entry" role="listitem">
De Chaisemartin, Clément, and Xavier D’Haultfœuille. 2020. <span>“Two-Way Fixed Effects Estimators with Heterogeneous Treatment Effects.”</span> <em>American Economic Review</em> 110 (9): 2964–96.
</div>
<div id="ref-de2023twosurvey" class="csl-entry" role="listitem">
———. 2023. <span>“Two-Way Fixed Effects and Differences-in-Differences with Heterogeneous Treatment Effects: A Survey.”</span> <em>The Econometrics Journal</em> 26 (3): C1–30.
</div>
<div id="ref-deaton2010instruments" class="csl-entry" role="listitem">
Deaton, Angus. 2010. <span>“Instruments, Randomization, and Learning about Development.”</span> <em>Journal of Economic Literature</em> 48 (2): 424–55.
</div>
<div id="ref-goodman2021difference" class="csl-entry" role="listitem">
Goodman-Bacon, Andrew. 2021. <span>“Difference-in-Differences with Variation in Treatment Timing.”</span> <em>Journal of Econometrics</em> 225 (2): 254–77.
</div>
<div id="ref-heckman2008econometric" class="csl-entry" role="listitem">
Heckman, James J. 2008. <span>“Econometric Causality.”</span> <em>International Statistical Review</em> 76 (1): 1–27.
</div>
<div id="ref-heckman2024econometric" class="csl-entry" role="listitem">
Heckman, James J, and Rodrigo Pinto. 2024. <span>“Econometric Causality: The Central Role of Thought Experiments.”</span> <em>Journal of Econometrics</em>, 105719.
</div>
<div id="ref-hirano2003efficient" class="csl-entry" role="listitem">
Hirano, Keisuke, Guido W Imbens, and Geert Ridder. 2003. <span>“Efficient Estimation of Average Treatment Effects Using the Estimated Propensity Score.”</span> <em>Econometrica</em> 71 (4): 1161–89.
</div>
<div id="ref-hoover2008" class="csl-entry" role="listitem">
Hoover, Kevin D. 2008. <span>“The New Palgrave Dictionary of Economics.”</span> In, edited by Steven N. Durlauf and Lawrence E. Blume, 2nd ed. Palgrave Macmillan.
</div>
<div id="ref-imai2019should" class="csl-entry" role="listitem">
Imai, Kosuke, and In Song Kim. 2019. <span>“When Should We Use Unit Fixed Effects Regression Models for Causal Inference with Longitudinal Data?”</span> <em>American Journal of Political Science</em> 63 (2): 467–90.
</div>
<div id="ref-imbens2020potential" class="csl-entry" role="listitem">
Imbens, Guido W. 2020. <span>“Potential Outcome and Directed Acyclic Graph Approaches to Causality: Relevance for Empirical Practice in Economics.”</span> <em>Journal of Economic Literature</em> 58 (4): 1129–79.
</div>
<div id="ref-imbens2015" class="csl-entry" role="listitem">
Imbens, Guido W, and Donald B Rubin. 2015. <em>Causal Inference in Statistics, Social, and Biomedical Sciences</em>. Cambridge university press.
</div>
<div id="ref-imbens2009recent" class="csl-entry" role="listitem">
Imbens, Guido W, and Jeffrey M Wooldridge. 2009. <span>“Recent Developments in the Econometrics of Program Evaluation.”</span> <em>Journal of Economic Literature</em> 47 (1): 5–86.
</div>
<div id="ref-pearl2018" class="csl-entry" role="listitem">
Pearl, Judea, and Dana Mackenzie. 2018. <em>The Book of Why: The New Science of Cause and Effect</em>. Basic books.
</div>
<div id="ref-rosenbaum1983central" class="csl-entry" role="listitem">
Rosenbaum, Paul R, and Donald B Rubin. 1983. <span>“The Central Role of the Propensity Score in Observational Studies for Causal Effects.”</span> <em>Biometrika</em> 70 (1): 41–55.
</div>
<div id="ref-rubin1975bayesian" class="csl-entry" role="listitem">
Rubin, Donald B. 1975. <span>“Bayesian Inference for Causality: The Importance of Randomization.”</span> In <em>The Proceedings of the Social Statistics Section of the American Statistical Association</em>, 233:239. American Statistical Association Alexandria, VA.
</div>
<div id="ref-sun2021estimating" class="csl-entry" role="listitem">
Sun, Liyang, and Sarah Abraham. 2021. <span>“Estimating Dynamic Treatment Effects in Event Studies with Heterogeneous Treatment Effects.”</span> <em>Journal of Econometrics</em> 225 (2): 175–99.
</div>
<div id="ref-verbeek2017" class="csl-entry" role="listitem">
Verbeek, Marno. 2017. <em>A Guide to Modern Econometrics</em>. John Wiley &amp; Sons.
</div>
<div id="ref-wooldridge2003cluster" class="csl-entry" role="listitem">
Wooldridge, Jeffrey M. 2003. <span>“Cluster-Sample Methods in Applied Econometrics.”</span> <em>American Economic Review</em> 93 (2): 133–38.
</div>
<div id="ref-wooldridge2023simple" class="csl-entry" role="listitem">
———. 2023. <span>“Simple Approaches to Nonlinear Difference-in-Differences with Panel Data.”</span> <em>The Econometrics Journal</em> 26 (3): C31–66.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Here, I follow the notation of Guido W. Imbens. You should be comfortable with alternative notations, such as superscripts (<span class="math inline">\(Y^1_{i},Y^0_{i}\)</span>) and subscripts (<span class="math inline">\(Y_{i1},Y_{i0}\)</span>; as in MM and MHE).<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>This statement can be generalized to continuous treatment, but it will require some assumptions regarding the causal relationship.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Here, I am using super-population notation. This means that each <span class="math inline">\(i\)</span> is thought of as an <em>independent</em> draw from a potentially infinite super-population. For finite sample analysis, the vectors of potential outcomes are treated as non-random. It is only the assignment vector, <span class="math inline">\(D\)</span>, that is random. You would therefore define unconfoundedness as independence across the full vectors of potential outcomes: <span class="math inline">\(Y(1),Y(0)\perp D |X\)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>This is equivalent to including the control function: <span class="math inline">\(Y = \beta_1 + \beta_2 Z + \beta_3M_ZD + \varepsilon\)</span>.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>