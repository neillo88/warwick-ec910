[
  {
    "objectID": "problem-set-4-solution.html",
    "href": "problem-set-4-solution.html",
    "title": "Problem Set 4 (SOLUTIONS)",
    "section": "",
    "text": "This problem set will revisit some of the material covered in Handouts 3 and 4. You will be required to work with a ‘raw’ dataset, downloaded from an online repository. For this reason, you should take care to check how the data is coded.\nYou will be using a version of the US Current Population Survey (CPS) called the Merged Outgoing Rotation Group (MORG). This data is compiled by the National Bureau of Economic Research (NBER) and has been used in many famous studies of the US economy. The CPS has a rather unique rotating panel design: “The monthly CPS is a rotating panel design; households are interviewed for four consecutive months, are not in the sample for the next eight months, and then are interviewed for four more consecutive months.” (source: IPUMS). The NBER’s MORG keeps only the outgoing rotation group’s observations.\nThe MORG .dta files can be found at: https://data.nber.org/morg/annual/."
  },
  {
    "objectID": "problem-set-4-solution.html#preamble",
    "href": "problem-set-4-solution.html#preamble",
    "title": "Problem Set 4 (SOLUTIONS)",
    "section": "Preamble",
    "text": "Preamble\n\n\n\n\n\nCreate a do-file for this problem set and include a preamble that sets the directory and opens the data directly from the NBER website. Of course, this requires a good internet connection. For example,\n\nclear \n//or, to remove all stored values (including macros, matrices, scalars, etc.) \n*clear all\n\n* Replace $rootdir with the relevant path to on your local harddrive.\ncd \"$rootdir/problem-sets/ps-4\"\n\ncap log close\nlog using problem-set-4-log.txt, replace\n\nuse \"https://data.nber.org/morg/annual/morg19.dta\", clear\n\nYou can, of course, download the data and open it locally on your computer."
  },
  {
    "objectID": "problem-set-4-solution.html#questions",
    "href": "problem-set-4-solution.html#questions",
    "title": "Problem Set 4 (SOLUTIONS)",
    "section": "Questions",
    "text": "Questions\n1. Create a new variable exper equal to age minus (years of education + 6). This is referred to as potential years of experience. Check how each variable defines missing values before proceeding. You will need to create a years of education variable for this. Here is he the suggested code:\n\ntab grade92, m\ngen eduyrs = .\n    replace eduyrs = .3 if grade92==31\n    replace eduyrs = 3.2 if grade92==32\n    replace eduyrs = 7.2 if grade92==33\n    replace eduyrs = 7.2 if grade92==34\n    replace eduyrs = 9  if grade92==35\n    replace eduyrs = 10 if grade92==36\n    replace eduyrs = 11 if grade92==37\n    replace eduyrs = 12 if grade92==38\n    replace eduyrs = 12 if grade92==39\n    replace eduyrs = 13 if grade92==40\n    replace eduyrs = 14 if grade92==41\n    replace eduyrs = 14 if grade92==42\n    replace eduyrs = 16 if grade92==43\n    replace eduyrs = 18 if grade92==44\n    replace eduyrs = 18 if grade92==45\n    replace eduyrs = 18 if grade92==46\n    lab var eduyrs \"completed education\"\ntab grade92, sum(eduyrs)\n\n\n    Highest |\n      grade |\n  completed |      Freq.     Percent        Cum.\n------------+-----------------------------------\n         31 |        814        0.28        0.28\n         32 |      1,495        0.51        0.79\n         33 |      3,071        1.05        1.85\n         34 |      4,123        1.41        3.26\n         35 |      5,244        1.80        5.06\n         36 |      7,824        2.69        7.75\n         37 |      9,271        3.18       10.93\n         38 |      4,226        1.45       12.38\n         39 |     82,795       28.41       40.79\n         40 |     50,112       17.20       57.99\n         41 |     12,392        4.25       62.24\n         42 |     16,161        5.55       67.79\n         43 |     59,438       20.40       88.19\n         44 |     25,374        8.71       96.89\n         45 |      3,785        1.30       98.19\n         46 |      5,265        1.81      100.00\n------------+-----------------------------------\n      Total |    291,390      100.00\n(291,390 missing values generated)\n(814 real changes made)\n(1,495 real changes made)\n(3,071 real changes made)\n(4,123 real changes made)\n(5,244 real changes made)\n(7,824 real changes made)\n(9,271 real changes made)\n(4,226 real changes made)\n(82,795 real changes made)\n(50,112 real changes made)\n(12,392 real changes made)\n(16,161 real changes made)\n(59,438 real changes made)\n(25,374 real changes made)\n(3,785 real changes made)\n(5,265 real changes made)\n\n    Highest |\n      grade |   Summary of completed education\n  completed |        Mean   Std. dev.       Freq.\n------------+------------------------------------\n         31 |   .30000001           0         814\n         32 |         3.2           0       1,495\n         33 |   7.1999998           0       3,071\n         34 |   7.1999998           0       4,123\n         35 |           9           0       5,244\n         36 |          10           0       7,824\n         37 |          11           0       9,271\n         38 |          12           0       4,226\n         39 |          12           0      82,795\n         40 |          13           0      50,112\n         41 |          14           0      12,392\n         42 |          14           0      16,161\n         43 |          16           0      59,438\n         44 |          18           0      25,374\n         45 |          18           0       3,785\n         46 |          18           0       5,265\n------------+------------------------------------\n      Total |   13.556855   2.7030576     291,390\n\n\n\ntab age, m\ngen exper = age-(eduyrs+6)\n\n\n        Age |      Freq.     Percent        Cum.\n------------+-----------------------------------\n         16 |      4,661        1.60        1.60\n         17 |      4,630        1.59        3.19\n         18 |      4,417        1.52        4.70\n         19 |      4,039        1.39        6.09\n         20 |      3,915        1.34        7.43\n         21 |      3,996        1.37        8.81\n         22 |      3,918        1.34       10.15\n         23 |      3,950        1.36       11.51\n         24 |      4,194        1.44       12.94\n         25 |      4,185        1.44       14.38\n         26 |      4,325        1.48       15.87\n         27 |      4,476        1.54       17.40\n         28 |      4,600        1.58       18.98\n         29 |      4,633        1.59       20.57\n         30 |      4,829        1.66       22.23\n         31 |      4,735        1.62       23.85\n         32 |      4,601        1.58       25.43\n         33 |      4,748        1.63       27.06\n         34 |      4,646        1.59       28.66\n         35 |      4,730        1.62       30.28\n         36 |      4,742        1.63       31.91\n         37 |      4,848        1.66       33.57\n         38 |      4,550        1.56       35.13\n         39 |      4,735        1.62       36.76\n         40 |      4,667        1.60       38.36\n         41 |      4,503        1.55       39.90\n         42 |      4,390        1.51       41.41\n         43 |      4,309        1.48       42.89\n         44 |      4,193        1.44       44.33\n         45 |      4,253        1.46       45.79\n         46 |      4,266        1.46       47.25\n         47 |      4,447        1.53       48.78\n         48 |      4,563        1.57       50.34\n         49 |      4,698        1.61       51.96\n         50 |      4,646        1.59       53.55\n         51 |      4,477        1.54       55.09\n         52 |      4,555        1.56       56.65\n         53 |      4,523        1.55       58.20\n         54 |      4,736        1.63       59.83\n         55 |      5,010        1.72       61.55\n         56 |      5,035        1.73       63.27\n         57 |      4,976        1.71       64.98\n         58 |      5,030        1.73       66.71\n         59 |      5,066        1.74       68.45\n         60 |      5,124        1.76       70.20\n         61 |      5,067        1.74       71.94\n         62 |      5,035        1.73       73.67\n         63 |      4,927        1.69       75.36\n         64 |      4,892        1.68       77.04\n         65 |      4,554        1.56       78.60\n         66 |      4,526        1.55       80.16\n         67 |      4,344        1.49       81.65\n         68 |      4,328        1.49       83.13\n         69 |      4,100        1.41       84.54\n         70 |      4,058        1.39       85.93\n         71 |      4,008        1.38       87.31\n         72 |      3,897        1.34       88.65\n         73 |      3,147        1.08       89.73\n         74 |      2,815        0.97       90.69\n         75 |      2,809        0.96       91.66\n         76 |      2,623        0.90       92.56\n         77 |      2,373        0.81       93.37\n         78 |      2,201        0.76       94.13\n         79 |      1,977        0.68       94.80\n         80 |      7,799        2.68       97.48\n         85 |      7,340        2.52      100.00\n------------+-----------------------------------\n      Total |    291,390      100.00\n\n\n2. Keep only those between the ages of 18 and 54. Check the distribution of `exper’ and replace any negative values to 0.\n\nkeep if inrange(age,18,54)\nsum exper, det\nreplace exper=0 if exper&lt;0\n\n(126,352 observations deleted)\n\n                            exper\n-------------------------------------------------------------\n      Percentiles      Smallest\n 1%            0             -6\n 5%            1             -5\n10%            2             -4       Obs             165,038\n25%            7             -4       Sum of wgt.     165,038\n\n50%           16                      Mean           16.50623\n                        Largest       Std. dev.      10.57401\n75%           25           47.7\n90%           31           47.7       Variance       111.8097\n95%           34           47.7       Skewness       .1296908\n99%           36           47.7       Kurtosis       1.887811\n(1,078 real changes made)\n\n\n3. Create a categorical variable that takes on 4 values: 1 “less than High School”; 2 “High School Diploma”; 3 “some Higher Education”; 4 “Bachelors”; 5 “Postgraduate”. This variable should be based on the the grade921 variable. You can find the value labels for this variable in this document: &lt;https://data.nber.org/morg/docs/cpsx.pdf&gt;. I suggest using therecodecommand, which allows you to create value labels while assigning values. Check the distributio ofexper` by education category.\n\nrecode grade92 (31/38 = 1 \"&lt;HS\") (39 = 2 \"HS\") (40/42 = 3 \"HS+\") (43 = 4 \"BA\") (44/46 = 5 \"PG\"), gen(educat)\ntab grade92 educat, m\n\ntab educat, sum(exper)\n\n(165,038 differences between grade92 and educat)\n\n   Highest |\n     grade |      RECODE of grade92 (Highest grade completed)\n completed |       &lt;HS         HS        HS+         BA         PG |     Total\n-----------+-------------------------------------------------------+----------\n        31 |       398          0          0          0          0 |       398 \n        32 |       578          0          0          0          0 |       578 \n        33 |     1,515          0          0          0          0 |     1,515 \n        34 |     1,571          0          0          0          0 |     1,571 \n        35 |     1,971          0          0          0          0 |     1,971 \n        36 |     2,198          0          0          0          0 |     2,198 \n        37 |     4,373          0          0          0          0 |     4,373 \n        38 |     2,440          0          0          0          0 |     2,440 \n        39 |         0     45,013          0          0          0 |    45,013 \n        40 |         0          0     30,934          0          0 |    30,934 \n        41 |         0          0      7,154          0          0 |     7,154 \n        42 |         0          0      9,708          0          0 |     9,708 \n        43 |         0          0          0     37,557          0 |    37,557 \n        44 |         0          0          0          0     14,804 |    14,804 \n        45 |         0          0          0          0      2,021 |     2,021 \n        46 |         0          0          0          0      2,803 |     2,803 \n-----------+-------------------------------------------------------+----------\n     Total |    15,044     45,013     47,796     37,557     19,628 |   165,038 \n\n  RECODE of |\n    grade92 |\n   (Highest |\n      grade |          Summary of exper\n completed) |        Mean   Std. dev.       Freq.\n------------+------------------------------------\n        &lt;HS |    19.29665    12.82301      15,044\n         HS |   17.726435   11.044222      45,013\n        HS+ |   15.643589   10.806949      47,796\n         BA |   15.376841   9.3440749      37,557\n         PG |   15.900092   8.1569821      19,628\n------------+------------------------------------\n      Total |   16.514468   10.560511     165,038\n\n\n4. Create the variable lnwage equal to the (natural) log of weekly earnings. Create a figure that shows the predicted linear fit of lwage against exper, by educat. Try to place all 5 fitted lines in the same graph.\n\ngen lnwage = ln(earnwke)\ntwoway (lfit lnwage exper if educat==1) (lfit lnwage exper if educat==2)  (lfit lnwage exper if educat==3) (lfit lnwage exper if educat==4) (lfit lnwage exper if educat==5) , legend(order(1 \"&lt;HS\" 2 \"HS\" 3 \"HS+\" 4 \"BA\" 5 \"PG\") pos(6) r(1)) xtitle(Years of experience) \n\n(49,686 missing values generated)\n\n\n\n\n\n\n\n\n\n5. Estimate a linear regression model that allows the slope coefficient on exper and constant term to vary by education category (educat). Let the base (excluded) education category be 2 “High School diploma”.\n\\[\n  \\ln(Wage_i) = \\alpha + \\sum_{j\\neq2}\\psi_j \\mathbf{1}\\{Educat_i=j\\} + \\beta Exper_i + \\sum_{j\\neq2}\\gamma_j Exper_i\\times\\mathbf{1}\\{Educat_i=j\\}+\\upsilon_i\n\\]\n\nreg lnwage ib2.educat##c.exper\n\n\n      Source |       SS           df       MS      Number of obs   =   115,352\n-------------+----------------------------------   F(9, 115342)    =   4039.95\n       Model |  17435.5509         9  1937.28343   Prob &gt; F        =    0.0000\n    Residual |  55310.0589   115,342  .479530951   R-squared       =    0.2397\n-------------+----------------------------------   Adj R-squared   =    0.2396\n       Total |  72745.6098   115,351   .63064568   Root MSE        =    .69248\n\n------------------------------------------------------------------------------\n      lnwage | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      educat |\n        &lt;HS  |  -.3882762   .0178644   -21.73   0.000    -.4232902   -.3532622\n        HS+  |  -.0839435   .0104229    -8.05   0.000    -.1043722   -.0635149\n         BA  |   .6145964   .0109763    55.99   0.000     .5930831    .6361097\n         PG  |   .9055692   .0141961    63.79   0.000      .877745    .9333933\n             |\n       exper |   .0182621   .0003709    49.24   0.000     .0175351    .0189891\n             |\n      educat#|\n     c.exper |\n        &lt;HS  |    .001037   .0007627     1.36   0.174     -.000458    .0025319\n        HS+  |   .0095156   .0005186    18.35   0.000     .0084991    .0105321\n         BA  |  -.0032067   .0005743    -5.58   0.000    -.0043324   -.0020811\n         PG  |  -.0051215   .0007698    -6.65   0.000    -.0066302   -.0036128\n             |\n       _cons |   6.101809   .0077485   787.48   0.000     6.086622    6.116996\n------------------------------------------------------------------------------\n\n\n6. Show that after 13 years of experience, those with some Higer Education (but no Bachelors), out earn those with just a high school diploma. You can assume that there are is a 2 year difference between the experience (education).\n\ndis _b[exper]*14\ndis (_b[exper] + _b[3.educat#exper])*12 + _b[3.educat]\n\n\ndis _b[exper]*15\ndis (_b[exper] + _b[3.educat#exper])*13 + _b[3.educat]\n\n.25566943\n.24938901\n.27393153\n.27716672\n\n\n7. Use the post-estimation test command to test the null hypothesis: \\(H_0: 15\\beta = 13(\\beta+\\gamma_3)+\\psi_3\\).\n\ntest exper*15 = (exper+3.educat#exper)*13+3.educat\n\n\n ( 1)  - 3.educat + 2*exper - 13*3.educat#c.exper = 0\n\n       F(  1,115342) =    0.32\n            Prob &gt; F =    0.5734\n\n\n8. Estimate a transformed version of the above model allowing you to test the above hypothesis using the coefficient from a single regressor. That is, the resulting test should be a simple t-test of \\(H_0: \\phi=0\\), where \\(\\phi\\) is the coefficient on the interaction of exper and a dummy variable for educat=3. This will be easier to do if you estimate the model using only the relevant sample: those with High School diplomas and some Higher Education. I suggest avoiding the use of factor notation to create the dummy variables and interaction terms for this exercise. For example, the following should replicate the relevant coefficients from Q5.\n\ngen hasHE = educat==3 if inlist(educat,2,3)\ngen hasHEexp = hasHE*exper\n\nreg lnwage exper hasHE hasHEexp\n\n(72,229 missing values generated)\n(72,229 missing values generated)\n\n      Source |       SS           df       MS      Number of obs   =    62,811\n-------------+----------------------------------   F(3, 62807)     =   2860.46\n       Model |  4000.16053         3  1333.38684   Prob &gt; F        =    0.0000\n    Residual |  29277.0845    62,807  .466143655   R-squared       =    0.1202\n-------------+----------------------------------   Adj R-squared   =    0.1202\n       Total |  33277.2451    62,810  .529808073   Root MSE        =    .68275\n\n------------------------------------------------------------------------------\n      lnwage | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       exper |   .0182621   .0003657    49.94   0.000     .0175453    .0189789\n       hasHE |  -.0839435   .0102764    -8.17   0.000    -.1040852   -.0638019\n    hasHEexp |   .0095156   .0005113    18.61   0.000     .0085134    .0105178\n       _cons |   6.101809   .0076396   798.71   0.000     6.086835    6.116782\n------------------------------------------------------------------------------\n\n\n\ngen experR = exper+hasHEexp*2/13\ngen hasHER = hasHE-hasHEexp/13\nreg lnwage experR hasHER hasHEexp\n\n(72,229 missing values generated)\n(72,229 missing values generated)\n\n      Source |       SS           df       MS      Number of obs   =    62,811\n-------------+----------------------------------   F(3, 62807)     =   2860.46\n       Model |  4000.16052         3  1333.38684   Prob &gt; F        =    0.0000\n    Residual |  29277.0845    62,807  .466143655   R-squared       =    0.1202\n-------------+----------------------------------   Adj R-squared   =    0.1202\n       Total |  33277.2451    62,810  .529808073   Root MSE        =    .68275\n\n------------------------------------------------------------------------------\n      lnwage | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      experR |   .0182621   .0003657    49.94   0.000     .0175453    .0189789\n      hasHER |  -.0839435   .0102764    -8.17   0.000    -.1040852   -.0638019\n    hasHEexp |   .0002489   .0004358     0.57   0.568    -.0006053     .001103\n       _cons |   6.101809   .0076396   798.71   0.000     6.086835    6.116782\n------------------------------------------------------------------------------\n\n\n9. Verify that the F-statistic from Q7 is the square of the above T-statistic.\n\ndis (_b[hasHEexp]/_se[hasHEexp])^2\n\n.32610143\n\n\n10. Use the restricted OLS approach to replicate the F-statistic and p-value from Q7.\n\nreg lnwage exper hasHE hasHEexp\nscalar RSSu = e(rss)\nscalar DOFu = e(df_r)\nreg lnwage experR hasHER \nscalar RSSr = e(rss)\nscalar DOFr = e(df_r)\n\nscalar Fstat = ((RSSr-RSSu)/(DOFr-DOFu))/(RSSu/DOFu)\nscalar pval = Ftail(1,DOFu,Fstat)\n\nscalar list Fstat pval\n\n\n      Source |       SS           df       MS      Number of obs   =    62,811\n-------------+----------------------------------   F(3, 62807)     =   2860.46\n       Model |  4000.16053         3  1333.38684   Prob &gt; F        =    0.0000\n    Residual |  29277.0845    62,807  .466143655   R-squared       =    0.1202\n-------------+----------------------------------   Adj R-squared   =    0.1202\n       Total |  33277.2451    62,810  .529808073   Root MSE        =    .68275\n\n------------------------------------------------------------------------------\n      lnwage | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       exper |   .0182621   .0003657    49.94   0.000     .0175453    .0189789\n       hasHE |  -.0839435   .0102764    -8.17   0.000    -.1040852   -.0638019\n    hasHEexp |   .0095156   .0005113    18.61   0.000     .0085134    .0105178\n       _cons |   6.101809   .0076396   798.71   0.000     6.086835    6.116782\n------------------------------------------------------------------------------\n\n      Source |       SS           df       MS      Number of obs   =    62,811\n-------------+----------------------------------   F(2, 62808)     =   4290.58\n       Model |  4000.00851         2  2000.00425   Prob &gt; F        =    0.0000\n    Residual |  29277.2366    62,808  .466138654   R-squared       =    0.1202\n-------------+----------------------------------   Adj R-squared   =    0.1202\n       Total |  33277.2451    62,810  .529808073   Root MSE        =    .68274\n\n------------------------------------------------------------------------------\n      lnwage | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      experR |   .0182233   .0003593    50.71   0.000      .017519    .0189277\n      hasHER |  -.0882792   .0069253   -12.75   0.000    -.1018527   -.0747056\n       _cons |   6.104077   .0065255   935.42   0.000     6.091287    6.116867\n------------------------------------------------------------------------------\n     Fstat =  .32612066\n      pval =   .5679544\n\n\n11. Use the restricted OLS approach to test the following hypothesis corresponding to the model in Q5:\n\\[\nH_0: \\gamma_j = 0\\qquad \\text{for}\\quad j=1,3,4,5\n\\] Compute the F-statistic and p-value. Verify your result using the post-estimation test command.\n\nreg lnwage ib2.educat##c.exper\nscalar RSSu = e(rss)\nscalar DOFu = e(df_r)\nreg lnwage ib2.educat exper \nscalar RSSr = e(rss)\nscalar DOFr = e(df_r)\n\nscalar Fstat = ((RSSr-RSSu)/(DOFr-DOFu))/(RSSu/DOFu)\nscalar pval = Ftail(DOFr-DOFu,DOFu,Fstat)\n\nscalar list Fstat pval\n\n** verify\nreg lnwage ib2.educat##c.exper\ntest 1.educat#exper 3.educat#exper 4.educat#exper 5.educat#exper\n\n\n      Source |       SS           df       MS      Number of obs   =   115,352\n-------------+----------------------------------   F(9, 115342)    =   4039.95\n       Model |  17435.5509         9  1937.28343   Prob &gt; F        =    0.0000\n    Residual |  55310.0589   115,342  .479530951   R-squared       =    0.2397\n-------------+----------------------------------   Adj R-squared   =    0.2396\n       Total |  72745.6098   115,351   .63064568   Root MSE        =    .69248\n\n------------------------------------------------------------------------------\n      lnwage | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      educat |\n        &lt;HS  |  -.3882762   .0178644   -21.73   0.000    -.4232902   -.3532622\n        HS+  |  -.0839435   .0104229    -8.05   0.000    -.1043722   -.0635149\n         BA  |   .6145964   .0109763    55.99   0.000     .5930831    .6361097\n         PG  |   .9055692   .0141961    63.79   0.000      .877745    .9333933\n             |\n       exper |   .0182621   .0003709    49.24   0.000     .0175351    .0189891\n             |\n      educat#|\n     c.exper |\n        &lt;HS  |    .001037   .0007627     1.36   0.174     -.000458    .0025319\n        HS+  |   .0095156   .0005186    18.35   0.000     .0084991    .0105321\n         BA  |  -.0032067   .0005743    -5.58   0.000    -.0043324   -.0020811\n         PG  |  -.0051215   .0007698    -6.65   0.000    -.0066302   -.0036128\n             |\n       _cons |   6.101809   .0077485   787.48   0.000     6.086622    6.116996\n------------------------------------------------------------------------------\n\n      Source |       SS           df       MS      Number of obs   =   115,352\n-------------+----------------------------------   F(5, 115346)    =   7085.67\n       Model |  17093.4651         5  3418.69301   Prob &gt; F        =    0.0000\n    Residual |  55652.1448   115,346  .482480058   R-squared       =    0.2350\n-------------+----------------------------------   Adj R-squared   =    0.2349\n       Total |  72745.6098   115,351   .63064568   Root MSE        =    .69461\n\n------------------------------------------------------------------------------\n      lnwage | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      educat |\n        &lt;HS  |  -.3724213   .0090073   -41.35   0.000    -.3900754   -.3547671\n        HS+  |   .0726614   .0055618    13.06   0.000     .0617604    .0835624\n         BA  |   .5714202   .0057563    99.27   0.000     .5601379    .5827025\n         PG  |   .8295498   .0068114   121.79   0.000     .8161996    .8428999\n             |\n       exper |   .0201711   .0002025    99.60   0.000     .0197742    .0205681\n       _cons |   6.067685   .0054116  1121.24   0.000     6.057079    6.078292\n------------------------------------------------------------------------------\n     Fstat =  178.34399\n      pval =  1.32e-152\n\n      Source |       SS           df       MS      Number of obs   =   115,352\n-------------+----------------------------------   F(9, 115342)    =   4039.95\n       Model |  17435.5509         9  1937.28343   Prob &gt; F        =    0.0000\n    Residual |  55310.0589   115,342  .479530951   R-squared       =    0.2397\n-------------+----------------------------------   Adj R-squared   =    0.2396\n       Total |  72745.6098   115,351   .63064568   Root MSE        =    .69248\n\n------------------------------------------------------------------------------\n      lnwage | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      educat |\n        &lt;HS  |  -.3882762   .0178644   -21.73   0.000    -.4232902   -.3532622\n        HS+  |  -.0839435   .0104229    -8.05   0.000    -.1043722   -.0635149\n         BA  |   .6145964   .0109763    55.99   0.000     .5930831    .6361097\n         PG  |   .9055692   .0141961    63.79   0.000      .877745    .9333933\n             |\n       exper |   .0182621   .0003709    49.24   0.000     .0175351    .0189891\n             |\n      educat#|\n     c.exper |\n        &lt;HS  |    .001037   .0007627     1.36   0.174     -.000458    .0025319\n        HS+  |   .0095156   .0005186    18.35   0.000     .0084991    .0105321\n         BA  |  -.0032067   .0005743    -5.58   0.000    -.0043324   -.0020811\n         PG  |  -.0051215   .0007698    -6.65   0.000    -.0066302   -.0036128\n             |\n       _cons |   6.101809   .0077485   787.48   0.000     6.086622    6.116996\n------------------------------------------------------------------------------\n\n ( 1)  1.educat#c.exper = 0\n ( 2)  3.educat#c.exper = 0\n ( 3)  4.educat#c.exper = 0\n ( 4)  5.educat#c.exper = 0\n\n       F(  4,115342) =  178.34\n            Prob &gt; F =    0.0000\n\n\n12. Compute the relevant Chi-squared distributed test statistic and corresponding p-value for the above test, assuming \\(n\\) is large (enough).\n\nscalar Cstat = Fstat*(DOFr-DOFu)\nscalar pval = chi2tail(DOFr-DOFu,Cstat)\nscalar list Cstat pval\n\n     Cstat =  713.37597\n      pval =  4.42e-153\n\n\n13. Using the data from Problem Set 2, estimate the simple linear regression model using OLS,\n\\[\n  \\ln(Wage_i) = \\beta_0 + \\beta_1 Educ_i + \\beta_2 Female_i + \\varepsilon_i\n\\]\n\nuse \"$rootdir/problem-sets/ps-2/problem-set-2-data.dta\", clear\nreg lwage educ female\nest sto ols\nestadd scalar sigma = e(rmse)\n\n(PSID wage data 1976-82 from Baltagi and Khanti-Akom (1990))\n\n      Source |       SS           df       MS      Number of obs   =     4,165\n-------------+----------------------------------   F(2, 4162)      =    732.99\n       Model |  231.021419         2   115.51071   Prob &gt; F        =    0.0000\n    Residual |  655.883483     4,162  .157588535   R-squared       =    0.2605\n-------------+----------------------------------   Adj R-squared   =    0.2601\n       Total |  886.904902     4,164  .212993492   Root MSE        =    .39697\n\n------------------------------------------------------------------------------\n       lwage | Coefficient  Std. err.      t    P&gt;|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        educ |   .0651382   .0022066    29.52   0.000     .0608121    .0694642\n      female |  -.4737645   .0194589   -24.35   0.000    -.5119143   -.4356147\n       _cons |    5.89297   .0290891   202.58   0.000      5.83594        5.95\n------------------------------------------------------------------------------\n\nadded scalar:\n              e(sigma) =  .39697422\n\n\n14. Estimate the Mincer equation using Maximum Likelihood. Take a look at https://www.stata.com/manuals13/rmlexp.pdf, the documentation for the mlexp command. It has a discussion on estimating the CLRM using ML.1\n\nmlexp (ln(normalden(lwage, {xb: educ female _cons}, exp({theta}))))\nereturn list\nnlcom (sigma: exp(_b[/theta]))\nestadd scalar sigma = r(b)[1,1]\neststo ml\n\n\nInitial:      Log likelihood = -97095.356\nAlternative:  Log likelihood = -35297.969\nRescale:      Log likelihood = -12999.606\nRescale eq:   Log likelihood = -7350.6222\nIteration 0:  Log likelihood = -7350.6222  (not concave)\nIteration 1:  Log likelihood =  -3936.054  \nIteration 2:  Log likelihood = -2187.1092  (backed up)\nIteration 3:  Log likelihood = -2073.0429  \nIteration 4:  Log likelihood = -2060.4271  \nIteration 5:  Log likelihood = -2060.4019  \nIteration 6:  Log likelihood = -2060.4019  \n\nMaximum likelihood estimation\n\nLog likelihood = -2060.4019                              Number of obs = 4,165\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nxb           |\n        educ |   .0651382   .0022058    29.53   0.000      .060815    .0694614\n      female |  -.4737645   .0194519   -24.36   0.000    -.5118895   -.4356396\n       _cons |    5.89297   .0290786   202.66   0.000     5.835977    5.949963\n-------------+----------------------------------------------------------------\n      /theta |  -.9242442   .0109566   -84.35   0.000    -.9457188   -.9027696\n------------------------------------------------------------------------------\n\nscalars:\n               e(rank) =  4\n                  e(N) =  4165\n                 e(ic) =  6\n                  e(k) =  4\n               e(k_eq) =  2\n          e(converged) =  1\n                 e(rc) =  0\n                 e(ll) =  -2060.40189888505\n              e(k_aux) =  1\n               e(df_m) =  4\n         e(k_eq_model) =  0\n\nmacros:\n            e(cmdline) : \"mlexp (ln(normalden(lwage, {xb: educ female _cons..\"\n                e(cmd) : \"mlexp\"\n            e(predict) : \"mlexp_p\"\n          e(estat_cmd) : \"mlexp_estat\"\n       e(marginsnotok) : \"SCores\"\n          e(marginsok) : \"default xb\"\n        e(marginsprop) : \"nochainrule\"\n               e(lexp) : \"ln(normalden(lwage,{xb:},exp({theta:})))\"\n             e(params) : \"xb:educ xb:female xb:_cons theta:_cons\"\n                e(opt) : \"moptimize\"\n                e(vce) : \"oim\"\n          e(ml_method) : \"lf0\"\n          e(technique) : \"nr\"\n         e(properties) : \"b V\"\n\nmatrices:\n                  e(b) :  1 x 4\n                  e(V) :  4 x 4\n               e(init) :  1 x 4\n               e(ilog) :  1 x 20\n           e(gradient) :  1 x 4\n\nfunctions:\n             e(sample)   \n\n       sigma: exp(_b[/theta])\n\n------------------------------------------------------------------------------\n             | Coefficient  Std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       sigma |   .3968312   .0043479    91.27   0.000     .3883094     .405353\n------------------------------------------------------------------------------\n\nadded scalar:\n              e(sigma) =  .39683123\n\n\n15. Estimate the Mincer equation using Method of Moments. You can use the gmm command in Stata. Hint: the regressors will be their own instruments and use the onestep option.2\n\ngmm (lwage - {xb: educ female _cons}), instruments(educ female) onestep\neststo mm\n\nesttab ols ml mm, se drop(theta:_cons) scalar(N sigma) mtitle(OLS ML MM)\n\n\nStep 1\nIteration 0:  GMM criterion Q(b) =  44.629069  \nIteration 1:  GMM criterion Q(b) =  2.101e-24  \nIteration 2:  GMM criterion Q(b) =  1.368e-31  \n\nnote: model is exactly identified.\n\nGMM estimation \n\nNumber of parameters =   3\nNumber of moments    =   3\nInitial weight matrix: Unadjusted                 Number of obs   =      4,165\n\n------------------------------------------------------------------------------\n             |               Robust\n             | Coefficient  std. err.      z    P&gt;|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        educ |   .0651382   .0023187    28.09   0.000     .0605935    .0696828\n      female |  -.4737645   .0177811   -26.64   0.000    -.5086148   -.4389143\n       _cons |    5.89297   .0300924   195.83   0.000      5.83399     5.95195\n------------------------------------------------------------------------------\nInstruments for equation 1: educ female _cons\n\n------------------------------------------------------------\n                      (1)             (2)             (3)   \n                      OLS              ML              MM   \n------------------------------------------------------------\nmain                                                        \neduc               0.0651***       0.0651***       0.0651***\n                (0.00221)       (0.00221)       (0.00232)   \n\nfemale             -0.474***       -0.474***       -0.474***\n                 (0.0195)        (0.0195)        (0.0178)   \n\n_cons               5.893***        5.893***        5.893***\n                 (0.0291)        (0.0291)        (0.0301)   \n------------------------------------------------------------\nN                    4165            4165            4165   \nsigma               0.397           0.397                   \n------------------------------------------------------------\nStandard errors in parentheses\n* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001"
  },
  {
    "objectID": "problem-set-4-solution.html#postamble",
    "href": "problem-set-4-solution.html#postamble",
    "title": "Problem Set 4 (SOLUTIONS)",
    "section": "Postamble",
    "text": "Postamble\n\nlog close"
  },
  {
    "objectID": "problem-set-4-solution.html#footnotes",
    "href": "problem-set-4-solution.html#footnotes",
    "title": "Problem Set 4 (SOLUTIONS)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can also look at the following resource for a more flexible approach to ML estimation in Stata: https://www.stata.com/features/overview/maximum-likelihood-estimation/↩︎\nHere is a resource on GMM in Stata: https://www.stata.com/features/overview/generalized-method-of-moments/↩︎"
  }
]