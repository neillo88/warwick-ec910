{
  "hash": "91fca8f409d10bdef94f701bfa53ce74",
  "result": {
    "engine": "jupyter",
    "markdown": "---\nformat:\n  html: default\n  pdf: default\ntitle: Problem Set 3 (SOLUTIONS)\n---\n\n\n\n\n\nThe purpose of this problem set is for you to see how the ordinary least squares (OLS) estimator behaves under various assumptions in a linear regression model where you know what the model is â€“ since you are going to be generating the data from a known data generating process (DGP).\n\nThe models estimated are simple bivariate regressions but the properties of the OLS estimator with vary with each case. This is demonstrated by changing the (a) distributional properties of the error term (variance-covariance structure), and (b) inducing correlation between the regressor and the error term. Any resulting bias and/or inconsistency will depend on the DGP.\n\nTo achieve certain results we will have to use a serially-correlated error structure, which is only appropriate in a time-series setting. For this reason, the models will be written with subscript $t$ and not $i$. \n\nThe code has been provided for model 1. You can then modify the code for models 2-4. \n\n## Preamble\n\n\n::: {#87d4fab4 .cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<style>div.jp-Notebook .datagrid-container {min-height: 448px; }</style>\n```\n:::\n:::\n\n\nYou do not need to load data for this problem set.\n\n::: {#b421fe81 .cell execution_count=2}\n``` {.stata .cell-code}\nclear \n//or, to remove all stored values (including macros, matrices, scalars, etc.) \n*clear all\n\n* Replace $rootdir with the relevant path to on your local harddrive.\ncd \"$rootdir/problem-sets/ps-3\"\n\ncap log close\nlog using problem-set-3-log.txt, replace\n```\n:::\n\n\nHowever, since we are going to generate random variables, we should set a seed. This ensures replicability of the exercise. The number you choose is arbitrary, it simply ensures that any algorithms used to generate (pseudo) random variables start at the same place. \n\n::: {#014240f2 .cell execution_count=3}\n``` {.stata .cell-code}\nset seed 981836\n```\n:::\n\n\n## Model 1: CLRM\n\nThis is your classical linear regression model. OLS estimator is unbiased and consistent.\n\n$$\nY_t = \\beta_1 + \\beta_2X_t + \\upsilon_t \\qquad \\text{with}\\quad \\upsilon_t\\sim N(0,\\sigma^2)\n$$\n\nWe know that the OLS estimator for $\\beta_2$ is given by,\n\n$$\n\\begin{aligned}\n  \\hat{\\beta}_2 =& \\frac{\\sum_t \\big[(X_t-\\bar{X})(Y_t-\\bar{Y})\\big]}{\\sum_t (X_t-\\bar{X})^2} \\\\\n  =& \\beta_2 + \\frac{\\sum_t \\big[(X_t-\\bar{X})(\\upsilon_t-\\bar{\\upsilon})\\big]}{\\sum_t (X_t-\\bar{X})^2} \\\\\n  =& \\beta_2 + \\frac{\\sum_t \\tilde{X}_t\\tilde{\\upsilon}_t}{\\sum_t \\tilde{X}_t^2}\n\\end{aligned}  \n$$\nwhere $\\tilde{X}_t$ and $\\tilde{\\upsilon}_t$ represent the demeaned counterparts of these variables. Alternatively, using linear algebra notation:\n\n$$\n\\begin{aligned}\n  \\hat{\\beta}_2 =& \\frac{X'M_{\\ell}Y}{X'M_{\\ell}X} \\\\\n  =& \\beta_2 + \\frac{X'M_{\\ell}\\upsilon}{X'M_{\\ell}X} \\\\\n  =& \\beta_2 + \\frac{\\tilde{X}'\\tilde{\\upsilon}}{\\tilde{X}'\\tilde{X}}\n\\end{aligned}  \n$$\nwhere $\\tilde{X} = M_{\\ell}X$, $\\tilde{\\upsilon}= M_{\\ell}\\upsilon$, and $M_{\\ell} = I_n-\\ell(\\ell'\\ell)^{-1}\\ell'$ (the orthogonal projection of the constant regressor).\n\nWe know from Handouts 2 & 3, \n\n1.    $E[\\hat{\\beta}_2] = \\beta_2$ (i.e., unbiased)\n\n2.    $p \\lim \\hat{\\beta}_2 = \\beta_2$ (i.e., consistent)\n\n**Can you demonstrate these results?**\n\n### Simulation\n\nBegin by designing a programme that takes the parameters of the model as arguments, generates the data, estimates the model, and then returns the stored values. \n\n::: {#c535e4bd .cell execution_count=4}\n``` {.stata .cell-code}\ncap prog drop mc1\nprogram define mc1, rclass\n\tsyntax [, obs(integer 1) s(real 1) b1(real 0) b2(real 0)  sigma(real 1)]\n\tdrop _all\n\tset obs `obs'\n\tgen u = rnormal(0,`sigma')\t          // sigma is the std deviation of the error distribution\n\tgen x=uniform()*`s'                   // s is the std devation of the x distribution\n\tgen y=`b1'+`b2'*x + u\t                // this generates the dep variable y\n\treg y x\n\treturn scalar b1=_b[_cons]            // intercept estimate\n\treturn scalar b2=_b[x]\t\t            // coeff on the x variable\n\treturn scalar se2 = _se[x]            // std error\n    return scalar t2 = _b[x]/_se[x]     // t ratio\nend\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n```\n:::\n:::\n\n\nUse the the `simulate` command in Stata to estimate the model 100 times:\n\n::: {#4ff313ec .cell execution_count=5}\n``` {.stata .cell-code}\nsimulate b1=r(b1) b2=r(b2) se2=r(se2) t2=r(t2), reps(100): mc1, obs(50) s(6) b1(4) b2(2) sigma(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n      Command: mc1, obs(50) s(6) b1(4) b2(2) sigma(3)\n           b1: r(b1)\n           b2: r(b2)\n          se2: r(se2)\n           t2: r(t2)\n\nSimulations (100): .........10.........20.........30.........40.........50.....\n> ....60.........70.........80.........90.........100 done\n```\n:::\n:::\n\n\nCalculate the bias and plot the distribution of the bias. \n\n::: {#c5013c8f .cell execution_count=6}\n``` {.stata .cell-code}\ngen bias2=b2-2\nsu b1 b2 se2 t2\nsu bias2\nhistogram bias2, normal xline(`r(mean)')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n          b1 |        100    3.880226    .9977415   1.080851   6.090028\n          b2 |        100    2.041985     .271704   1.365155   2.673303\n         se2 |        100    .2520885    .0291596   .1814694   .3255497\n          t2 |        100    8.216185      1.4968   5.484826   12.60699\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       bias2 |        100    .0419852     .271704  -.6348448   .6733029\n(bin=10, start=-.63484478, width=.13081477)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](problem-set-3-solutions_files/figure-html/cell-7-output-2.png){}\n:::\n:::\n\n\n## Model 2: Serial Correlation\n\nRelax the assumption of an iid error term and allow for serial correlation. The OLS estimator is unbiased and consistent. However, the std errors are wrong since the software does not know that you have serially correlated errors and you are not taking this into account in the estimation.\n\n$$\nY_t = \\beta_1 + \\beta_2X_t + \\upsilon_t \\qquad \\text{where}\\quad \\upsilon_t = \\rho \\upsilon_{t-1}+\\varepsilon_t \\quad\\text{and}\\quad \\varepsilon_t\\sim N(0,\\sigma^2)\n$$\nWe say that $U_t$ follows an AR(1) process. You can show that $\\hat{\\beta}_2$ remains unbiased and consistant. However, the standard homoskedastic-variance estimator is incorrect:\n\n$$\nVar(\\hat{\\beta}_2) \\neq \\frac{\\sigma^2}{Var(X_i)}\n$$\n\n### Simulation\n\n::: {#31e55992 .cell execution_count=7}\n``` {.stata .cell-code}\ncap prog drop mc2\nprogram define mc2, rclass\n\tsyntax [, obs(integer 1) s(real 1) b1(real 0) b2(real 0) bias2(real 0) sigma(real 1) rho(real 0)]\n\tdrop _all\n\tset obs `obs'\n\tgen u=0 \n\tgen time=_n\n\ttsset time\n\tgen e = rnormal(0,`sigma')\t\n\tforvalues i=2/`obs'  {\n\treplace u=`rho'*u[_n-1] + e if _n==`i'\n\t}\n\tgen x=uniform()*`s'\n\tgen y=`b1'+`b2'*x + u\n\treg y x\t\t\n\treturn scalar b1=_b[_cons]\n\treturn scalar b2=_b[x]\n\treturn scalar se2 = _se[x]\n    return scalar t2 = _b[x]/_se[x]\nend\n\nsimulate b2=r(b2) se2=r(se2) t2=r(t2), reps(100): mc2, obs(30) s(6) b1(4) b2(2) sigma(3) rho(0.2) /**********/\ngen bias2=b2-2\nsu b2 t2 se2\nsu bias2\nhistogram bias2, normal xline(`r(mean)')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n      Command: mc2, obs(30) s(6) b1(4) b2(2) sigma(3) rho(0.2)\n           b2: r(b2)\n          se2: r(se2)\n           t2: r(t2)\n\nSimulations (100): .........10.........20.........30.........40.........50.....\n> ....60.........70.........80.........90.........100 done\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n          b2 |        100    2.027336    .3287378   1.284326    2.83436\n          t2 |        100    6.309408    1.478218   3.236439   10.17626\n         se2 |        100    .3301718    .0526629   .2165523   .4499786\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       bias2 |        100    .0273363    .3287378  -.7156742   .8343601\n(bin=10, start=-.71567416, width=.15500343)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](problem-set-3-solutions_files/figure-html/cell-8-output-2.png){}\n:::\n:::\n\n\n## Model 3: Dynamic model without serial correlation\n\nConsider a version of Model 1, where the regressor is the lag of the dependent variable. \n$$\nY_t = \\beta_1 + \\beta_2Y_{t-1} + \\upsilon_t \\qquad \\text{with}\\quad \\upsilon_t\\sim N(0,\\sigma^2)\n$$\nThe OLS estimator is now, \n$$\n  \\hat{\\beta}_2 = \\beta_2 + \\frac{\\sum_t \\tilde{Y}_{t-1}\\tilde{\\upsilon}_t}{\\sum_t \\tilde{Y}_{t-1}^2}\n$$\nThis model is biased, since\n\n$$\nE\\bigg[\\frac{\\sum_t \\tilde{Y}_{t-1}\\tilde{\\upsilon}_t}{\\sum_t \\tilde{Y}_{t-1}^2}\\bigg] \\neq \\frac{E\\big[\\sum_t \\tilde{Y}_{t-1}\\tilde{\\upsilon}_t\\big]}{E\\big[\\sum_t \\tilde{Y}_{t-1}^2\\big]}\n$$\nWhen the regressor was $X_t$, the above statement was true given the Law of Iterated Expectations. However, you can use Slutsky's theorem and the WLLN to show that $\\hat{\\beta}_2\\rightarrow_p \\beta_2$. This result relies on the fact that $Y_{t-1}$ is realized before $\\upsilon_t$ which is iid. Thus, the bias goes to 0 as $n\\rightarrow \\infty$. \n\n### Simulation\n\n::: {#ede4fc94 .cell execution_count=8}\n``` {.stata .cell-code}\ncap prog drop mc3\nprogram define mc3, rclass\n\tsyntax [, obs(integer 1)  g1(real 0)  g2(real 0)  sigma(real 1)]\n\tdrop _all\n\tset obs `obs'\n\tgen y=0\n\tgen u = rnormal(0,`sigma') \n\tgen time=_n\n\ttsset time\n\tforvalues i=2/`obs'  {\n\treplace y=`g1'+ `g2'* y[_n-1] + u  if _n==`i'\n\t}\n\treg y  L.y\n\treturn scalar g1=_b[_cons]\n\treturn scalar g2=_b[L.y]\n\treturn scalar se2 = _se[L.y]\n  return scalar t2 = _b[L.y]/_se[L.y]\nend\n\n\nsimulate  g2=r(g2) se2=r(se2) t2=r(t2), reps(100): mc3, obs(30) g1(4)  g2(0.20) sigma(3)   /**************/\ng bias2=g2-0.20\nsu g2 t2 se2 \nsu bias2\nhistogram bias2, normal xline(`r(mean)')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n      Command: mc3, obs(30) g1(4) g2(0.20) sigma(3)\n           g2: r(g2)\n          se2: r(se2)\n           t2: r(t2)\n\nSimulations (100): .........10.........20.........30.........40.........50.....\n> ....60.........70.........80.........90.........100 done\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n          g2 |        100    .1656964    .1610075  -.1987682   .5684798\n          t2 |        100     .931305    .9285551  -1.082788   3.572202\n         se2 |        100    .1824637    .0075315   .1591399   .2018857\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       bias2 |        100   -.0343036    .1610075  -.3987682   .3684798\n(bin=10, start=-.39876819, width=.0767248)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](problem-set-3-solutions_files/figure-html/cell-9-output-2.png){}\n:::\n:::\n\n\n## Model 4: Dynamic model with serial correlation\nConsider a version of Model 2, where the regressor is the lag of the dependent variable. \n$$\nY_t = \\beta_1 + \\beta_2Y_{t-1} + \\upsilon_t \\text{where}\\quad \\upsilon_t = \\rho \\upsilon_{t-1}+\\varepsilon_t \\quad\\text{and}\\quad \\varepsilon_t\\sim N(0,\\sigma^2)\n$$\nAs with model 3, the OLS estimator will be biased. In addition, since $Cov(\\upsilon_t,\\upsilon_{t-1})\\neq0$ and $Cov(Y_t,\\upsilon_{t})\\neq 0$ (for any $t$), \n$$\n\\Rightarrow Cov(Y_{t-1},\\upsilon_{t})\\neq 0\n$$\nAs a result $\\hat{\\beta}_2$ is inconsistent. \n\n### Simulation\n\n::: {#07cd8a9e .cell execution_count=9}\n``` {.stata .cell-code}\ncap prog drop mc4\nprogram define mc4, rclass\n\tsyntax [, obs(integer 1)  g1(real 0)  g2(real 0)  sigma(real 1) rho(real 0) ]\n\tdrop _all\n\tset obs `obs'\n\tgen y=0\n\tgen u=0\n\tgen e = rnormal(0,`sigma') \n\tgen time=_n\n\ttsset time\n\t\n\tforvalues i=2/`obs'  {\n\treplace u=`rho'*u[_n-1] + e if _n==`i'\n\treplace y=`g1'+ `g2'* y[_n-1] + u  if _n==`i'\n\t}\n\treg y  L.y\n\treturn scalar g1=_b[_cons]\n\treturn scalar g2=_b[L.y]\n\treturn scalar se2 = _se[L.y]\n  return scalar t2 = _b[L.y]/_se[L.y]\nend\n\nsimulate  g2=r(g2) se2=r(se2) t2=r(t2), reps(100): mc4, obs(30) g1(4) g2(0.20) sigma(3) rho(0.2)  /***********/\ng bias2=g2-0.20\nsu g2 t2 se2\nsu bias2\nhistogram bias2, normal xline(`r(mean)')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n      Command: mc4, obs(30) g1(4) g2(0.20) sigma(3) rho(0.2)\n           g2: r(g2)\n          se2: r(se2)\n           t2: r(t2)\n\nSimulations (100): .........10.........20.........30.........40.........50.....\n> ....60.........70.........80.........90.........100 done\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n          g2 |        100    .2905161    .1457775   -.110407   .5824866\n          t2 |        100    1.682558    .9099479   -.630446   3.896481\n         se2 |        100    .1767967    .0106219   .1494904    .219561\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       bias2 |        100    .0905161    .1457775   -.310407   .3824866\n(bin=10, start=-.31040695, width=.06928935)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](problem-set-3-solutions_files/figure-html/cell-10-output-2.png){}\n:::\n:::\n\n\n## Postamble\n\n::: {#99bba2b9 .cell execution_count=10}\n``` {.stata .cell-code}\nlog close\n```\n:::\n\n\n",
    "supporting": [
      "problem-set-3-solutions_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}