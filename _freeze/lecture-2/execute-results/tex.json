{
  "hash": "2d8bf670a2ad321645ea4ed9d31d6d4c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Estimators and their Properties\nformat:\n  html:\n    toc-depth: 3           # Set the depth of the table of contents\n    number-sections: true  # Number the sections in the HTML output\n    resources: \n      - \"lecture-2.pdf\" # Make the PDF file available for download\n    code-fold: true   # places code in dropdown\n  pdf:\n    #documentclass: article # LaTeX class used for the PDF document\n    toc: true              # Include a table of contents in the PDF output\n    number-sections: true  # Number the sections in the PDF output\n    keep-md: false          # Optionally keep the intermediate markdown file\n    output-file: \"lecture-2.pdf\" # Specify the PDF output file name\n    echo: false  # hides code\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Overview\n\nIn this handout we will investigate the *desirable* properties of an estimator. Further reading can be found in:\n\n-   Appendix A of @cameron2005\n-   Section 2.6 of @verbeek2017\n\n## An estimator\n\nAn estimator is a rule that tells you how to get your *estimate* given the observed data. As it is a that it is a function of random variables, **an estimator is a random variable** itself.\n\nWithout further information, we do not know anything about the distribution of this random variable and, in practice, will typically have to estimate the parameters of this distribution: mean, variance, skewness.\n\nThe *assumed* model (or data generating process) may pin down certain parameters or distributions. For example, under assumpions CLRM 5 & 6 the ordinary least squares estimator for $\\beta$ will be normally distributed.\n\n## Properties of estimators\n\nWhen evaluating an estimator you want to consider:\n\n1.  *bias*: does the estimator yield estimates that 'hit the right target' **on average**?\n\n2.  *efficiency*: do the estimates generated by the estimator have a limited dispersion/variance?\n\n3.  *distribution*: do you know the exact/approximate distribution of the estimator with which you can construct a valid hypothesis test?\n\nIt is important to consider both the small sample and large sample (asymptotic) properties of an estimator.\n\nUnbiasedness (property 1) is typically emphasized over properties 2 and 3. Afterall, a precise estimator of the wrong target is not particularly useful. That said, the expected value of an estimator is not always well defined.\n\n::: callout-important\nThese are properties of the *estimator*, a random variable, and not the *estimate*. The estimate is a just a constant: a non-random realization of the estimator.\n:::\n\n### Small vs large sample properties\n\nSometimes it is easier to study the large-sample, or *asymptotic*, properties of an estimator. That is, the properties of the estimator as the sample size gets large: $n\\rightarrow \\infty$.\n\nSmall-sample properties include:\n\n-   Biasedness\n\n-   Efficiency/variance\n\n-   Finite-sample distribution\n\nLarge-sample properties include:\n\n-   Consistency\n\n-   Asymptotic distribution\n\nAn estimator can have an asymptotic variance (efficiency); although, in EC910 will mostly discuss estimators with variances that shrink to zero as $n\\rightarrow \\infty$.\n\n::: {.important-prop title=\"Important\"}\nThe phrase \"finite-sample\" is also used in other contexts. For example, in the Causal Inference (or Treatment Effects) literature \"finite-sample\" is used to describe *estimands*. This literature distinguishes between finite-sample and super-population estimands. The former relate to settings where the sample is treated as fixed, while the latter to settings where the sample is take as a draw from an unknown super population.\n\nThe estimator for a super-population estimand will have both finite and asymptotic properities.\n:::\n\n### Bias\n\nThe estimator $\\hat{\\theta}$ is **unbiased** for $\\theta$ if,\n\n$$\nE(\\hat{\\theta}) = \\theta\n$$ $\\hat{\\theta}$ is a function of sample size, $n$, while $\\theta$ is not. Some texts will use the notation $\\hat{\\theta}_n$ to emphasize this point.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture-2_files/figure-pdf/unnamed-chunk-2-1.pdf)\n:::\n:::\n\n\n\n### Efficiency\n\nEfficiency is a relative concept. The estimator $\\hat{\\theta}$ is more efficient the estimator $\\tilde{\\theta}$, if both are unbiased for $\\theta$ **and**\n\n$$\nVar(\\hat{\\theta})<Var(\\tilde{\\theta})\n$$ What if the estimator is biased? We can use Mean Square Error:\n\n::: {#def-mse}\n#### MSE\n\n$MSE = E\\big[(\\hat{\\theta}-\\theta)^2\\big] = \\text{bias}^2+\\text{variance}$\n:::\n\nNote, the above definition assumes that a finite variance.\n\n::: proof\n$$\n\\begin{aligned}\nE\\big[(\\hat{\\theta}-\\theta)^2\\big] &= E\\big[\\big((\\hat{\\theta}-E[\\hat{\\theta}])-(E[\\hat{\\theta}]-\\theta)\\big)^2\\big] \\\\\n&=E\\big[(\\hat{\\theta}-E[\\hat{\\theta}])^2\\big]+ E\\big[(\\theta-E[\\hat{\\theta}])\\big] - 2E\\big[(\\hat{\\theta}-E[\\hat{\\theta}])(\\theta-E[\\hat{\\theta}])\\big] \\\\\n&=Var(\\hat{\\theta}) + \\text{bias}^2\n\\end{aligned}\n$$\n:::\n\nThe first line adds and subtracts the mean of the estimator, which need not be $\\theta$, the targetted population parameter. The second expands the outside exponent over the two bracketted terms.\n\nThe cross-product term in line 2 is 0. [Can you show this?]{style=\"color: blue;\"}\n\n### Consistency\n\nConsistency is an asumptotic property of an estimator.\n\n::: {#def-consistency}\nThe estimator $\\hat{\\theta}_n$ is a consistent estimator of $\\theta$ if it converges in probability to $\\theta$ as $n\\rightarrow\\infty$,\n\n$$\nPr(|\\hat{\\theta}_n-\\theta|\\geq\\varepsilon)\\rightarrow 0\\qquad n\\rightarrow 0\n$$ for $\\varepsilon$ very small.[^1]\n:::\n\n[^1]: $|x-a|>b\\; \\implies \\;-b>x-a\\quad\\text{and}\\quad b<x-a$\n\nIntuitively, this means that tail area probabilities (i.e. probability of an estimator very far from the true value) goes to zero as the sample size gets large.\n\nWe use the notations, $p\\lim$,\n\n$$\np\\lim\\hat{\\theta}_n = \\theta\n$$ \n\nor convergence in probability, \n\n$$\\hat{\\theta}_n \\rightarrow_p \\theta\\qquad\\text{as}\\qquad n\\rightarrow \\infty$$\n\nAn important theorem regarding the consistency of estimators is Slutzky's theorem concerning continuous functions of estimators. For example, we will use this theorem to prove the consistency of the OLS estimator.\n\n::: {#thm-slutzky}\n#### Slutzky's Theorem\n\nIf $p\\lim\\hat{\\theta}_n = \\theta$ and $h(\\cdot)$ is a continuous function, then\n\n$$\np\\lim\\;h(\\hat{\\theta}_n) = h\\big(p\\lim\\hat{\\theta}_n\\big)=h(\\theta)\n$$\n:::\n\nHere are some useful examples,\n\n::: {#exm-slutzky}\nGiven two consistent estimators $\\big[\\hat{\\theta}_n,\\hat{\\beta}_n\\big]$,\n\n1.  $p\\lim\\;(a\\hat{\\theta}_n+ b\\hat{\\beta}_n) = a(p\\lim\\;\\hat{\\theta}_n)+b(p\\lim\\;\\hat{\\beta}_n) =a\\theta +b\\beta$ for constants $a$ and $b$\n\n2.  $p\\lim\\;(\\hat{\\theta}_n\\times\\hat{\\beta}_n) = (p\\lim\\;\\hat{\\theta}_n)\\times (p\\lim\\;\\hat{\\beta}_n)=\\theta\\beta$\n\n3.  $p\\lim\\;(\\hat{\\theta}_n^2) = (p\\lim\\;\\hat{\\theta}_n)^2 = \\theta^2$\n\n4.  $p\\lim\\;\\bigg(\\frac{\\hat{\\theta}_n}{\\hat{\\beta}_n}\\bigg) = \\frac{\\theta}{\\beta}$\n\n5.  $p\\lim\\;\\exp(\\hat{\\theta}_n) = \\exp(p\\lim\\;\\hat{\\theta}_n) = \\exp(\\theta)$\n:::\n\nMSE convergence (to zero) is a **sufficient** condition for consistency. However, it is not a necessary.\n\nFor an *unbiased* estimator,\n\n$$\nVar(\\hat{\\theta}_n)\\rightarrow 0 \\quad \\text{as}\\quad n\\rightarrow 0 \\implies p\\lim\\hat{\\theta}_n = \\theta\n$$\n\nFor a biased estimator,\n\n$$\nMSE(\\hat{\\theta}_n)\\rightarrow 0 \\quad \\text{as}\\quad n\\rightarrow 0 \\implies p\\lim\\hat{\\theta}_n = \\theta\n$$\n\n::: {#exr-mseconv}\nGiven a sample of independently and identically distributed (iid) random variables, $$\nX_1,...,X_n \\sim N(\\mu,\\sigma^2)\n$$ Show that the mean estimator - $\\overline{X} = \\frac{1}{n}\\sum_{i=1}{n}X_i$ is a consistent estimator of $\\mu$; i.e. $p \\lim\\;\\overline{X} = \\mu$.\n:::\n\nThe above exercise relates to one of the most important examples of convergence in probability:\n\n::: {#thm-wlln}\n#### Weak Law of Large Numbers\n\nLet $X_1,...,X_n$ be a sample of iid random variables, such that $E|X_1|<\\infty$. Then, $$\nn^{-1}\\sum_{i=1}^{n}X_i \\rightarrow_p E[X_1]\\qquad \\text{as}\\qquad n\\rightarrow \\infty\n$$\n:::\n\nHere we use the notation $E[X_1]$, since the data is iid and $E[X_i]=E[X_1]$ for $i=1,...,n$. We prove a modified version of the WLLN theorem, assuming $E[X_1^2]<\\infty$. Since $E[X_1^2]<\\infty\\implies$ both $E|X_1|<\\infty$ and $Var(X_1)<\\infty$, we will have proven WLLN theorem.\n\n::: {#thm-wlln2}\nLet $X_1,...,X_n$ be a sample of iid random variables, such that $Var(X_1)<\\infty$. Then, $$\nn^{-1}\\sum_{i=1}^{n}X_i \\rightarrow_p E[X_1]\\qquad \\text{as}\\qquad n\\rightarrow \\infty\n$$\n:::\n\nTo complete the proof of WLLN, we will need to use Markov's Inequality. We will not prove this lemma, but versions of the proof are readily available online.\n\n::: {#lem-markov}\n#### Markov's Inequality\n\nLet $X$ be a random variable. For $\\varepsilon>0$ and $r>0$, then\n\n$$\nPr(|X|\\geq \\varepsilon)\\leq \\frac{E\\big[|X|^2\\big]}{\\varepsilon^2}\n$$\n:::\n\nNow, we can complete the proof of WLLN, assuming a finite second moment.\n\n::: proof\n$$\n\\begin{aligned}\nPr\\bigg(\\bigg|n^{-1}\\sum_{i=1}^{n}X_i - E[X_1]\\bigg|\\geq \\varepsilon\\bigg) &= Pr\\bigg(\\bigg|n^{-1}\\sum_{i=1}^{n}(X_i - E[X_1])\\bigg|\\geq \\varepsilon\\bigg) \\\\\n&\\leq \\frac{E\\big[|\\sum_{i=1}^{n}(X_i - E[X_1])|^2\\big]}{n^2\\varepsilon^2} \\\\\n&=\\frac{\\sum_{i=1}^{n}\\sum_{j=1}^{n}E\\big[(X_i - E[X_1])(X_j - E[X_1])\\big]}{n^2\\varepsilon^2} \\\\\n&=\\frac{\\sum_{i=1}^{n}E\\big[(X_i - E[X_1])^2\\big]}{n^2\\varepsilon^2} \\\\\n&=\\frac{nVar(X_1)}{n^2\\varepsilon^2} \\\\\n&\\rightarrow 0 \\qquad \\text{as}\\qquad n\\rightarrow \\infty\n\\end{aligned}\n$$\n:::\n\nNote, the WLLN holds under a weaker condition than iid. Between lines 3 and 4 we used the independence of observations to set correlations between units to 0. Thus, we required a weaker assumption of uncorrelateness: $Cov(X_i,X_j)=0\\;\\forall\\;i\\neq j$.\n\nUnder the WLLN, you can show that the sample variance converges in probability to the population variance.\n\n$$\np\\lim \\big(n^{-1}\\sum_{i=1}^{n}(X_i - \\overline{X})^2\\big) \\rightarrow_p Var(X_i)\n$$\n\n### Distribution\n\nIn this section we will focus on the asymptotic distribution of an estimator. If we know the joint distribution of the data, then we can *potentially* work out the distribution of the estimator in a finite sample. This is especially true when the random variables in question are drawn from known families of distributions.\n\nFor example, we know that the sum of Normal distributed random variables is Normally distributed itself. And the sum of the square of standard-Normally distributed random variables is Chi-squared distributed. We used these results do determine the distribution of test-statistics corresponding to the Classical Linear Regression Model.[^2]\n\n[^2]: In this setting, we make an assumption around the distribution of the error term in the model.\n\nHowever, what do you do when you do not know the underlying distribution of the random variables? Here we will rely on a the Central Limit Theorem, which tells us about the approximate distribution of an estimator when the sample is large.\n\nBefore discussing CLT, we must define a new convergence concept: convergence in distribution.\n\n::: {#def-condist}\nLet $X_1,...,X_n$ be a sequence of random variables and let $F_n(x)$ denote the marginal CDF of $X_n$, $$\nF_n(x) = Pr(X_n\\leq x)\n$$ Then, $X_n$ converges *in distribution* if $F_n(x)\\rightarrow F(x)$ as $n\\rightarrow \\infty$, where F(x) is continuous.\n:::\n\nConvergence in distribution can be denoted,\n\n$$\nX_n\\rightarrow_d X\n$$\n\nwhere X is a random variable with distribution function $F(x)$. Note, it is not the random variables that are converging, but rather the distributions of said random variables.\n\nAs with convergence in probability, there are some basic rules for manipulation.\n\n1.  The first is **Cramer Convergence Theorem**: Suppose $X_n\\rightarrow_dX$ and $Y_n\\rightarrow_p c$. then,\n    -   $X_n+Y_n\\rightarrow_d X+c$\n    -   $Y_nX_n\\rightarrow_d cX$\n    -   $X_n/Y_n\\rightarrow_d X/c$, for $c\\neq 0$\n2.  If $X_n\\rightarrow_p X$, then $X_n\\rightarrow_d X$. The converse is not true, with the exception:\n3.  If $X_n\\rightarrow_d C$, a constant, then $X_n\\rightarrow_p C$.\n4.  If $X_n-Y_n\\rightarrow_p 0$, and $Y_n\\rightarrow_d Y$, then $X_n\\rightarrow_d Y$.\n\nUnlike with convergence in probability, $X_n\\rightarrow_d X$ and $Y_n\\rightarrow_d Y$ does NOT imply $X_n + Y_n \\rightarrow_d X+Y$, unless joint convergences holds too. This is because the former are statements concerning the *marginal* distributions of $X_n$ and $Y_n$, while the distribution of $X_n + Y_n$ depends on the *joint* distribution.\n\nIf $(X_n,Y_n)\\rightarrow_d (X,Y)$ (joint convergence), then $X_n+Y_n\\rightarrow_dX+Y$. This result follows from the Central Mapping Theorem.\n\n::: {#thm-cmt}\n#### Continuous Mapping Theorem\nSuppose $X_n\\rightarrow_d X$ and let $h(\\cdot)$ be a continuous function. Then, $h(X_n)\\rightarrow_d h(X)$.\n:::\n\nCMT holds for a vector of random variables as well as single random variable. Thus, if\n\n$$\n\\begin{bmatrix}X_n \\\\ Y_n\\end{bmatrix}\\rightarrow_d \\begin{bmatrix}X \\\\ Y\\end{bmatrix}\n$$ then by CMT, $$\nX_n+Y_n=\\begin{bmatrix}1 & 1\\end{bmatrix}\\begin{bmatrix}X_n \\\\ Y_n\\end{bmatrix} \\rightarrow_d\\begin{bmatrix}1 & 1\\end{bmatrix}\\begin{bmatrix}X \\\\ Y\\end{bmatrix} = X+Y\n$$\n\nCan you show:\n\n-   $(X_n,Y_n)\\rightarrow_d (X,Y)$ (i.e. joint convergence) implies $X_n\\rightarrow_d X$ (i.e. marginal convergence)?\n-   $\\sum_{j=1}^k X_{jn}^2 \\sim \\chi^2_k$ for $X_n\\sim N(0,I_k)$, $X_n\\in \\mathbf{R}^k$.\n\nHaving discussed the CMT, we are now ready to discuss the Central Limit Theorem. Both are used extensively in Econometrics. We will not prove CLT as the proof requires a more detailed discussion of Moment Generating Functions. \n\nRecall, for an iid random sample, the sample converges in probability to the population mean:\n\n$$\np \\lim\\;\\overline{X} = E[X_1]\n$$\n\nThe rate of convergence for this estimator is $\\sqrt{n}$. The estimator is said to be root-$n$-consistent.\n\n::: {#thm-clt}\n#### Central Limit Theorem\n\nLet $X_1,...,X_n$ be a sample of iid random variables such that $E[X_1]=0$ and $0<E[X_1^2]<\\infty$. Then,\n\n$$\nn^{-1/2}\\sum_{i=1}^{n}X_i\\rightarrow_d N(0,E[X_1^2])\n$$\n:::\n\nConsider a random sample drawn independently from a distribution with mean $\\mu$ and variance $\\sigma$. Note, this distribution need not be Normal. It holds that, \\$X_1-\\mu,...,X_n-\\mu \\$ are iid and $E[X_1-\\mu]$. In addition, $E[(X_1-\\mu)^2]=\\sigma^2<\\infty$. Therefore, by CLT\n\n$$\nn^{1/2}(\\overline{X}-\\mu) = n^{-1/2}\\sum_{i=1}^{n}(X_i-\\mu)\\rightarrow_d N(0,\\sigma^2)\n$$\n\nIn practice, we use CLT to determine the *approximate* distribution of an estimator in large samples. Based on the above result, we can say\n\n$$ \nn^{1/2}(\\overline{X}-\\mu)\\overset{a}{\\sim} N(0,\\sigma^2)\n$$ or,\n\n$$ \n\\overline{X}\\overset{a}{\\sim}N(\\mu,\\sigma^2/n) \n$$\n\nwhere $\\sigma^2/n$ is referred to as the *asymptotic variance* of $\\overline{X}$. Here, the symbol $\\overset{a}{\\sim}$ can be interpreted as \"approximately in large samples\".\n\nWith CMT and CLT, we need one more theorem before we continue. We know from the WLLN that $\\overline{X}\\rightarrow_p E[X_1]=\\mu$. Moreover, by Slutzky's theorem we know that $h(\\overline{X})\\rightarrow_p h(\\mu)$, for $h(\\cdot)$ continuous. However, we do not know the approximate distribution of $h(\\overline{X})$ in a large sample. \n\nConsider, $h(\\mu)$ is a non-random constant and CLT applies to $n^{1/2}(\\overline{X}-\\mu)$ and not $\\overline{X}$. The latter implying that we cannot use CMT. \n\n::: {#thm-clt}\n#### Delta Method\nLet $\\hat{\\theta}_n$ be a random k-dimensional vector. Suppose that $n^{1/2}(\\hat{\\theta}_n-\\theta)\\rightarrow_d Y$, where $theta$ is a non-random k-dimensional vector and $Y$ a random k-dimensional vector. \n\nLet $h: \\mathbf{R}^k\\rightarrow\\mathbf{R}^m$ be a function (mapping) that is continuously differentiable on some open neighbourhood of $\\theta$. Then, \n\n$$\nn^{1/2}\\big(h(\\hat{\\theta}_n)-h(\\theta)\\big)\\rightarrow_d \\frac{\\partial h(\\theta)}{\\partial\\theta'}Y\n$$\n:::\n\nThe proof involves Cramer's Convergence Theorem, Slutzky's Theorem, as well as the Mean Value Theorem (which we have not discussed). This result is used to derive the limiting distribution of non-linear models and their marginal effects (e.g. probit/logit), as well as non-linear tests of regression coefficients. \n\n\n## Properties of the E\\[xpectation\\] operator {.appendix}\n\nThe expectation of a continuously-distributed, random variable $X$ can be defined as:\n\n$$\nE[X] = \\int_{-\\infty}^{\\infty}tf_Xdt = \\int_{-\\infty}^{\\infty}tdF_X(t)\n$$\n\nIf $X$ takes on discrete values, $X \\in \\mathbf{X} = \\{x_1,x_2,...,x_m\\}$, we can replace the integral with a summation and the probability density function (pdf: $f_X$) with a probability mass function (pmf: $p_X$).\n\n$$\nE[X] = \\sum_{t\\in \\mathbf{X}}tp_X(t)\n$$\n\nAn important property of the Exptation operator is that it is linear. Let $\\{a,b\\}$ be two constants (non-random scalars), then\n\n$$\nE[aX+b] = aE[X]+b\n$$\n\n[Can you show this, using the above definition of the expectation operator?]{style=\"color: blue;\"}\n\nSimilarly, consider two random varibales $X$ and $Y$. Then,\n\n$$\nE[aX + bY] = E[aX] + E[bY] = aE[X] + bE[Y]\n$$\n\nHowever, note\n\n1.  $E[XY] = E[X] \\times E[Y]$ **if** $X$ and $Y$ are independent\n\nThis follows from the fact that $f_{X,Y} = f_X\\cdot f_Y$ **if** $X$ and $Y$ are independent. Note, this is not an iff (if-and-only-if) statement.\n\n2.  $E\\left[\\frac{X}{Y}\\right]\\neq\\frac{E[X]}{E[Y]}$ for $E[Y]\\neq0$\n\n3.  $E[\\ln(X)]\\neq \\ln(E[Y])$\n\nIn general, $E[h(X)]\\neq h(E[Y])$ with the exception of $h(\\cdot)$ linear function.\n\n## References\n",
    "supporting": [
      "lecture-2_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}